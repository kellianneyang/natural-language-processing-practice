{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191a1fd8",
   "metadata": {},
   "source": [
    "# Word Embedding Techniques\n",
    "\n",
    "https://www.youtube.com/watch?v=Do8cVbx-HOs&list=PLeo1K3hjS3uuvuAXhYjV2lMEShq2UYSwX&index=19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d79ad",
   "metadata": {},
   "source": [
    "- Word2vec\n",
    "- GloVe\n",
    "- fastText\n",
    "\n",
    "Dense arrays, similar words will have similar vectors, shorter arrays (popular is 300 elements)\n",
    "\n",
    "Use continuous bag of words (CBOW) and skip grams to implement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72baf0",
   "metadata": {},
   "source": [
    "- BERT (parameter tuning: ALBERT, RoBERTa)\n",
    "- GPT\n",
    "\n",
    "Transformer-based embedding techniques (based on transformer architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222feb1",
   "metadata": {},
   "source": [
    "- ElMo\n",
    "\n",
    "Based on LSTM (Long Short-Term Memory RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26d07a",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "https://www.youtube.com/watch?v=hQwFeIupNP0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7985214",
   "metadata": {},
   "source": [
    "Feature vectors are learned as side effects by training neural networks to calculate probability of word given contextual word(s).\n",
    "\n",
    "Input layer of neural network is one-hot encoded vectors of previous and next context word(s) (however many previous and next words you include is called your window size; this is the continuous bag of words (CBOW) approach). Output should be the target word (also a one-hot encoded vector). The hidden layer has however many neurons. By back propagation, after however many epochs, the network will learn the weights on the neurons in the hidden layer. These weights, for each output word, are that word's dense word vector. The individual weights in the vector don't correspond to any real-world measurement (like semantic components). \n",
    "\n",
    "Another approach is skip grams, which is similar except that the network is trained to predict the context word(s) given the target word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335aef0c",
   "metadata": {},
   "source": [
    "# Gensim Code Tutorial\n",
    "\n",
    "https://www.youtube.com/watch?v=Q2NtCcqmIww\n",
    "\n",
    "Data: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz\n",
    "\n",
    "Note: downloads as zipped file (json.gz); to unzip, run command in gitbash: gunzip reviews_Cell_Phones_and_Accessories_5.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cb3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "# !pip install python-levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e856ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d054e0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin      reviewerName helpful  \\\n",
       "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
       "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
       "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
       "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
       "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  They look good and stick good! I just don't li...        4   \n",
       "1  These stickers work like the review says they ...        5   \n",
       "2  These are awesome and make my phone look so st...        5   \n",
       "3  Item arrived in great time and was in perfect ...        4   \n",
       "4  awesome! stays on, and looks great. can be use...        5   \n",
       "\n",
       "                                     summary  unixReviewTime   reviewTime  \n",
       "0                                 Looks Good      1400630400  05 21, 2014  \n",
       "1                      Really great product.      1389657600  01 14, 2014  \n",
       "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
       "3                                      Cute!      1382313600  10 21, 2013  \n",
       "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"reviews_Cell_Phones_and_Accessories_5.json\", \n",
    "                  lines = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8749b375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6d255",
   "metadata": {},
   "source": [
    "## Simple Preprocessing & Tokenization\n",
    "\n",
    "The first thing to do for any data science task is to clean the data. For NLP, we apply various processing like converting all the words to lower case, trimming spaces, removing punctuations. This is something we will do over here too.\n",
    "\n",
    "Additionally, we can also remove stop words like 'and', 'or', 'is', 'the', 'a', 'an' and convert words to their root forms like 'running' to 'run'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e9a87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [they, look, good, and, stick, good, just, don...\n",
       "1         [these, stickers, work, like, the, review, say...\n",
       "2         [these, are, awesome, and, make, my, phone, lo...\n",
       "3         [item, arrived, in, great, time, and, was, in,...\n",
       "4         [awesome, stays, on, and, looks, great, can, b...\n",
       "                                ...                        \n",
       "194434    [works, great, just, like, my, original, one, ...\n",
       "194435    [great, product, great, packaging, high, quali...\n",
       "194436    [this, is, great, cable, just, as, good, as, t...\n",
       "194437    [really, like, it, becasue, it, works, well, w...\n",
       "194438    [product, as, described, have, wasted, lot, of...\n",
       "Name: reviewText, Length: 194439, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we only want the 'reviewText' column\n",
    "# gensim.utils.simple_preprocessing: tokenize, remove punctuation,\n",
    "# lowercase, trim spaces\n",
    "review_text = df.reviewText.apply(gensim.utils.simple_preprocess)\n",
    "\n",
    "# now each review is a list of tokens\n",
    "review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d256fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'look',\n",
       " 'good',\n",
       " 'and',\n",
       " 'stick',\n",
       " 'good',\n",
       " 'just',\n",
       " 'don',\n",
       " 'like',\n",
       " 'the',\n",
       " 'rounded',\n",
       " 'shape',\n",
       " 'because',\n",
       " 'was',\n",
       " 'always',\n",
       " 'bumping',\n",
       " 'it',\n",
       " 'and',\n",
       " 'siri',\n",
       " 'kept',\n",
       " 'popping',\n",
       " 'up',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'irritating',\n",
       " 'just',\n",
       " 'won',\n",
       " 'buy',\n",
       " 'product',\n",
       " 'like',\n",
       " 'this',\n",
       " 'again']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232ab54",
   "metadata": {},
   "source": [
    "## Training the Word2Vec Model\n",
    "\n",
    "Train the model for reviews. Use a window of size 10 i.e. 10 words before the present word and 10 words ahead. A sentence with at least 2 words should only be considered, configure this using min_count parameter.\n",
    "\n",
    "Workers define how many CPU threads to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16dfb8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec4cc161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary\n",
    "\n",
    "model.build_vocab(review_text, progress_per = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132941e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194439"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709afbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0856f065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61500920, 83868975)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the word2vec model\n",
    "\n",
    "model.train(review_text, \n",
    "            total_examples = model.corpus_count,\n",
    "            epochs = model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3db93883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model so it can be reused elsewhere\n",
    "\n",
    "model.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46891b9a",
   "metadata": {},
   "source": [
    "## Finding similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3cca69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.6464673280715942),\n",
       " ('shabby', 0.6327041983604431),\n",
       " ('horrible', 0.5904310941696167),\n",
       " ('good', 0.585347592830658),\n",
       " ('awful', 0.545529842376709),\n",
       " ('poor', 0.5279961228370667),\n",
       " ('sad', 0.5254566073417664),\n",
       " ('disappointing', 0.5213345885276794),\n",
       " ('okay', 0.5137054324150085),\n",
       " ('crappy', 0.509948194026947)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e07acb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5457079"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1 = 'cheap', w2 = 'inexpensive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1974b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7778567"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1 = 'great', w2 = 'good')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f740a1f",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "You can read about gensim more at https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "Explore other Datasets related to Amazon Reviews: http://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6deba",
   "metadata": {},
   "source": [
    "# spaCy Word Vectors\n",
    "\n",
    "https://www.youtube.com/watch?v=vyohzuTkty8&list=PLeo1K3hjS3uuvuAXhYjV2lMEShq2UYSwX&index=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4bac0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
      "     -------------------------------------- 587.7/587.7 MB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from en-core-web-lg==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.23.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# word vectors are only included in spacy's medium or large\n",
    "# models\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d40f060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ca8df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog Vector: True OOV: False\n",
      "cat Vector: True OOV: False\n",
      "banana Vector: True OOV: False\n",
      "afskfsd Vector: False OOV: True\n"
     ]
    }
   ],
   "source": [
    "# check out if this model has vectors for some words\n",
    "\n",
    "doc = nlp(\"dog cat banana afskfsd\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, \n",
    "          \"Vector:\", token.has_vector, \n",
    "          \"OOV:\", token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7179111b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.2330e+00,  4.2963e+00, -7.9738e+00, -1.0121e+01,  1.8207e+00,\n",
       "        1.4098e+00, -4.5180e+00, -5.2261e+00, -2.9157e-01,  9.5234e-01,\n",
       "        6.9880e+00,  5.0637e+00, -5.5726e-03,  3.3395e+00,  6.4596e+00,\n",
       "       -6.3742e+00,  3.9045e-02, -3.9855e+00,  1.2085e+00, -1.3186e+00,\n",
       "       -4.8886e+00,  3.7066e+00, -2.8281e+00, -3.5447e+00,  7.6888e-01,\n",
       "        1.5016e+00, -4.3632e+00,  8.6480e+00, -5.9286e+00, -1.3055e+00,\n",
       "        8.3870e-01,  9.0137e-01, -1.7843e+00, -1.0148e+00,  2.7300e+00,\n",
       "       -6.9039e+00,  8.0413e-01,  7.4880e+00,  6.1078e+00, -4.2130e+00,\n",
       "       -1.5384e-01, -5.4995e+00,  1.0896e+01,  3.9278e+00, -1.3601e-01,\n",
       "        7.7732e-02,  3.2218e+00, -5.8777e+00,  6.1359e-01, -2.4287e+00,\n",
       "        6.2820e+00,  1.3461e+01,  4.3236e+00,  2.4266e+00, -2.6512e+00,\n",
       "        1.1577e+00,  5.0848e+00, -1.7058e+00,  3.3824e+00,  3.2850e+00,\n",
       "        1.0969e+00, -8.3711e+00, -1.5554e+00,  2.0296e+00, -2.6796e+00,\n",
       "       -6.9195e+00, -2.3386e+00, -1.9916e+00, -3.0450e+00,  2.4890e+00,\n",
       "        7.3247e+00,  1.3364e+00,  2.3828e-01,  8.4388e-02,  3.1480e+00,\n",
       "       -1.1128e+00, -3.5598e+00, -1.2115e-01, -2.0357e+00, -3.2731e+00,\n",
       "       -7.7205e+00,  4.0948e+00, -2.0732e+00,  2.0833e+00, -2.2803e+00,\n",
       "       -4.9850e+00,  9.7667e+00,  6.1779e+00, -1.0352e+01, -2.2268e+00,\n",
       "        2.5765e+00, -5.7440e+00,  5.5564e+00, -5.2735e+00,  3.0004e+00,\n",
       "       -4.2512e+00, -1.5682e+00,  2.2698e+00,  1.0491e+00, -9.0486e+00,\n",
       "        4.2936e+00,  1.8709e+00,  5.1985e+00, -1.3153e+00,  6.5224e+00,\n",
       "        4.0113e-01, -1.2583e+01,  3.6534e+00, -2.0961e+00,  1.0022e+00,\n",
       "       -1.7873e+00, -4.2555e+00,  7.7471e+00,  1.0173e+00,  3.1626e+00,\n",
       "        2.3558e+00,  3.3589e-01, -4.4178e+00,  5.0584e+00, -2.4118e+00,\n",
       "       -2.7445e+00,  3.4170e+00, -1.1574e+01, -2.6568e+00, -3.6933e+00,\n",
       "       -2.0398e+00,  5.0976e+00,  6.5249e+00,  3.3573e+00,  9.5334e-01,\n",
       "       -9.4430e-01, -9.4395e+00,  2.7867e+00, -1.7549e+00,  1.7287e+00,\n",
       "        3.4942e+00, -1.6883e+00, -3.5771e+00, -1.9013e+00,  2.2239e+00,\n",
       "       -5.4335e+00, -6.5724e+00, -6.7228e-01, -1.9748e+00, -3.1080e+00,\n",
       "       -1.8570e+00,  9.9496e-01,  8.9135e-01, -4.4254e+00,  3.3125e-01,\n",
       "        5.8815e+00,  1.9384e+00,  5.7294e-01, -2.8830e+00,  3.8087e+00,\n",
       "       -1.3095e+00,  5.9208e+00,  3.3620e+00,  3.3571e+00, -3.8807e-01,\n",
       "        9.0022e-01, -5.5742e+00, -4.2939e+00,  1.4992e+00, -4.7080e+00,\n",
       "       -2.9402e+00, -1.2259e+00,  3.0980e-01,  1.8858e+00, -1.9867e+00,\n",
       "       -2.3554e-01, -5.4535e-01, -2.1387e-01,  2.4797e+00,  5.9710e+00,\n",
       "       -7.1249e+00,  1.6257e+00, -1.5241e+00,  7.5974e-01,  1.4312e+00,\n",
       "        2.3641e+00, -3.5566e+00,  9.2066e-01,  4.4934e-01, -1.3233e+00,\n",
       "        3.1733e+00, -4.7059e+00, -1.2090e+01, -3.9241e-01, -6.8457e-01,\n",
       "       -3.6789e+00,  6.6279e+00, -2.9937e+00, -3.8361e+00,  1.3868e+00,\n",
       "       -4.9002e+00, -2.4299e+00,  6.4312e+00,  2.5056e+00, -4.5080e+00,\n",
       "       -5.1278e+00, -1.5585e+00, -3.0226e+00, -8.6811e-01, -1.1538e+00,\n",
       "       -1.0022e+00, -9.1651e-01, -4.7810e-01, -1.6084e+00, -2.7307e+00,\n",
       "        3.7080e+00,  7.7423e-01, -1.1085e+00, -6.8755e-01, -8.2901e+00,\n",
       "        3.2405e+00, -1.6108e-01, -6.2837e-01, -5.5960e+00, -4.4865e+00,\n",
       "        4.0115e-01, -3.7063e+00, -2.1704e+00,  4.0789e+00, -1.7973e+00,\n",
       "        8.9538e+00,  8.9421e-01, -4.8128e+00,  4.5367e+00, -3.2579e-01,\n",
       "       -5.2344e+00, -3.9766e+00, -2.1979e+00,  3.5699e+00,  1.4982e+00,\n",
       "        6.0972e+00, -1.9704e+00,  4.6522e+00, -3.7734e-01,  3.9101e-02,\n",
       "        2.5361e+00, -1.8096e+00,  8.7035e+00, -8.6372e+00, -3.5257e+00,\n",
       "        3.1034e+00,  3.2635e+00,  4.5437e+00, -5.7290e+00, -2.9141e-01,\n",
       "       -2.0011e+00,  8.5328e+00, -4.5064e+00, -4.8276e+00, -1.1786e+01,\n",
       "        3.5607e-01, -5.7115e+00,  6.3122e+00, -3.6650e+00,  3.3597e-01,\n",
       "        2.5017e+00, -3.5025e+00, -3.7891e+00, -3.1343e+00, -1.4429e+00,\n",
       "       -6.9119e+00, -2.6114e+00, -5.9757e-01,  3.7847e-01,  6.3187e+00,\n",
       "        2.8965e+00, -2.5397e+00,  1.8022e+00,  3.5486e+00,  4.4721e+00,\n",
       "       -4.8481e+00, -3.6252e+00,  4.0969e+00, -2.0081e+00, -2.0122e-01,\n",
       "        2.5244e+00, -6.8817e-01,  6.7184e-01, -7.0466e+00,  1.6641e+00,\n",
       "       -2.2308e+00, -3.8960e+00,  6.1320e+00, -8.0335e+00, -1.7130e+00,\n",
       "        2.5688e+00, -5.2547e+00,  6.9845e+00,  2.7835e-01, -6.4554e+00,\n",
       "       -2.1327e+00, -5.6515e+00,  1.1174e+01, -8.0568e+00,  5.7985e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out a vector\n",
    "\n",
    "# dog\n",
    "doc[0].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b14ab9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the shape of the spacy vector\n",
    "doc[0].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3fef10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.285995  ,  1.51985   , -3.1519876 , -4.857275  ,  0.40372053,\n",
       "       -0.702725  , -1.97505   , -1.9329001 , -0.79143   ,  0.99263746,\n",
       "        3.560485  ,  1.390425  ,  0.26564184,  2.01145   ,  3.3977425 ,\n",
       "       -3.612475  , -0.15815374, -2.1185076 ,  1.435475  , -1.710825  ,\n",
       "       -2.4027236 ,  2.909375  , -2.1509075 , -2.2286    , -0.668355  ,\n",
       "       -0.9713    , -2.6473498 ,  3.782715  , -2.5905025 , -0.33405   ,\n",
       "       -0.61644995, -0.599235  , -1.24345   , -0.14730498,  0.490825  ,\n",
       "       -4.184225  ,  1.0886575 ,  1.9182426 ,  2.1102002 , -2.239075  ,\n",
       "       -0.19210999, -2.6021075 ,  5.2194247 ,  2.7733    ,  1.3173975 ,\n",
       "        0.5136955 ,  1.3593975 , -1.86975   , -0.20521674, -1.4796726 ,\n",
       "        2.3111901 ,  5.665     ,  2.3114748 ,  0.7079749 , -0.90067494,\n",
       "        1.17948   ,  2.5487623 ,  0.68675   ,  1.7658175 ,  1.3378    ,\n",
       "        0.59345746, -3.6535451 ,  0.527775  ,  1.3896024 , -2.6922002 ,\n",
       "       -3.325725  , -1.3890749 , -0.874045  ,  0.09935001,  0.8764    ,\n",
       "        2.7730901 ,  1.0204074 ,  0.6353925 , -0.146353  ,  1.56624   ,\n",
       "       -1.063715  , -1.2923775 , -0.5483975 ,  0.75505   , -1.590275  ,\n",
       "       -2.441175  ,  1.866395  , -0.2400275 ,  1.5825524 , -0.49010497,\n",
       "       -2.6027002 ,  5.26835   ,  3.904525  , -5.131375  , -1.1495249 ,\n",
       "        1.4526074 , -0.8068825 ,  3.82475   , -3.8878498 ,  1.7805774 ,\n",
       "       -1.4031175 ,  0.29927504,  0.592625  , -0.08302999, -5.33      ,\n",
       "        1.0318698 ,  0.473675  ,  2.7173276 , -0.55807877,  1.6399775 ,\n",
       "        0.465081  , -6.4207    ,  3.11575   , -1.8556501 ,  1.710475  ,\n",
       "       -0.4622975 , -1.1671184 ,  4.36265   ,  0.02222002,  1.2222825 ,\n",
       "        0.588     ,  1.9822224 , -2.467175  ,  2.76445   , -0.67889994,\n",
       "       -0.7427    ,  2.245575  , -6.0123997 , -0.72527504, -1.87285   ,\n",
       "       -0.91846   ,  2.440125  ,  2.4540749 ,  1.4900725 ,  0.10703249,\n",
       "        0.047595  , -3.2942924 ,  1.239305  , -1.16957   ,  0.18462002,\n",
       "        1.2312449 , -1.386575  , -3.15465   , -0.913715  ,  0.74819994,\n",
       "       -1.9941449 , -3.203     ,  0.01737002, -1.353325  , -1.043985  ,\n",
       "       -1.0229825 ,  0.51056755,  0.3823375 , -0.67763746, -1.0248375 ,\n",
       "        2.4257798 ,  1.7865751 ,  0.31162998, -2.0303676 ,  1.5204852 ,\n",
       "        0.3485    ,  3.63475   ,  1.35194   ,  2.4262724 ,  0.24415755,\n",
       "        0.40569   , -2.0610101 , -1.307335  ,  0.95795506, -3.0141501 ,\n",
       "       -1.9653499 , -0.4448375 ,  0.639565  ,  1.1812375 , -0.60025   ,\n",
       "       -0.0109325 , -0.23046951, -0.10896751,  2.1220999 ,  1.2061851 ,\n",
       "       -3.37495   ,  1.3021424 ,  0.06811501,  0.15106004,  1.181785  ,\n",
       "        1.3460875 , -1.506175  , -0.35068998,  0.8152025 , -1.4061224 ,\n",
       "        0.59125   , -0.66874254, -5.103173  ,  0.0459325 , -1.6787925 ,\n",
       "       -0.7334672 ,  2.9973052 , -2.166325  , -1.5443001 ,  1.1422524 ,\n",
       "       -2.1521    , -1.64805   ,  3.4591    , -0.30703253, -1.305825  ,\n",
       "       -1.7171044 ,  0.15874998, -0.5684875 ,  0.46510255,  0.17225249,\n",
       "       -0.06735002,  0.15504299, -0.34052747, -0.66664994, -1.8667375 ,\n",
       "        2.8845248 ,  0.3691825 , -0.30275   , -0.1021975 , -2.8618503 ,\n",
       "        0.94210005,  0.7956675 , -0.2984025 , -2.5033576 , -1.2862749 ,\n",
       "        0.81129247, -2.2228    , -0.87005746,  1.67315   , -1.0649999 ,\n",
       "        3.20265   ,  1.4319775 , -2.564185  ,  2.32655   ,  0.56321746,\n",
       "       -3.389075  , -2.9358249 , -0.38588503,  0.921125  , -1.522875  ,\n",
       "        2.15642   , -1.579425  ,  2.2206402 ,  0.3008075 , -0.18837476,\n",
       "        1.2514024 ,  0.24397498,  2.684075  , -2.36275   , -1.17679   ,\n",
       "        0.26255003,  1.624775  ,  1.5111463 , -2.4778001 , -0.70549   ,\n",
       "       -2.47335   ,  3.1463773 , -2.73645   , -2.2671776 , -4.529025  ,\n",
       "       -0.56962   , -2.6018226 ,  4.854225  , -2.1018    , -0.470115  ,\n",
       "        1.1177975 , -1.4017751 , -2.539155  , -1.3725635 , -0.88435495,\n",
       "       -2.9191    , -0.95974994, -0.15434253, -0.2228925 ,  3.751525  ,\n",
       "        2.8053749 , -0.6664475 ,  1.239825  ,  1.5878824 ,  2.31563   ,\n",
       "       -2.389925  , -1.2239051 ,  1.4971274 , -0.83347   , -0.11096375,\n",
       "        0.2281825 , -1.3965625 ,  0.91313   , -2.404095  ,  0.9741    ,\n",
       "       -1.3312    , -1.937825  ,  2.6218026 , -2.7428    ,  0.04807997,\n",
       "        2.314675  , -2.478025  ,  4.321725  , -0.2115075 , -3.4397001 ,\n",
       "       -0.79958254, -2.183475  ,  4.17427   , -3.4088001 ,  1.9604499 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the vector for a whole doc is the average of the vectors\n",
    "# of the words in that doc\n",
    "doc.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99678db",
   "metadata": {},
   "source": [
    "## Compare similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b78a433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bread <-> bread: 1.0\n",
      "sandwich <-> bread: 0.6341067010130894\n",
      "burger <-> bread: 0.47520687769584247\n",
      "car <-> bread: 0.06451532596945217\n",
      "tiger <-> bread: 0.04764611272488976\n",
      "human <-> bread: 0.2151154210812192\n",
      "wheat <-> bread: 0.615036141030184\n"
     ]
    }
   ],
   "source": [
    "base_token = nlp(\"bread\")\n",
    "\n",
    "doc = nlp(\"bread sandwich burger car tiger human wheat\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text} <-> {base_token.text}:\", token.similarity(base_token))\n",
    "\n",
    "# higher scores (closer to 1) indicate more similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdd4440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper function to print similarity scores\n",
    "\n",
    "def print_similarity(base_word, words_to_compare):\n",
    "    base_token = nlp(base_word)\n",
    "    doc = nlp(words_to_compare)\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} <-> {base_token.text}:\", token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9821b8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple <-> iphone: 0.4387907748060368\n",
      "samsung <-> iphone: 0.6708590303423401\n",
      "iphone <-> iphone: 1.0\n",
      "dog <-> iphone: 0.08211864228011527\n",
      "kitten <-> iphone: 0.10222317834969896\n"
     ]
    }
   ],
   "source": [
    "print_similarity(\"iphone\", \"apple samsung iphone dog kitten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72862d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.9392200e+00, -2.3115001e+00, -1.3863000e+00, -1.9133999e+00,\n",
       "        4.1749401e+00, -1.5401300e+00, -3.8272700e+00,  5.0291996e+00,\n",
       "       -2.4454002e+00,  2.0851002e+00,  1.6605499e+01, -1.3788500e+00,\n",
       "       -5.7085404e+00,  2.7210798e+00,  6.6530025e-01,  3.4804001e+00,\n",
       "        1.0497000e+00, -1.1281996e+00, -6.6435003e-01, -3.5216696e+00,\n",
       "       -8.0680294e+00, -3.8434997e+00, -4.4948001e+00,  8.7943001e+00,\n",
       "       -6.3383985e-01, -4.8098001e+00, -1.2955203e+00, -6.1078286e-01,\n",
       "        4.1610003e-01, -4.1724200e+00,  3.7961500e+00, -5.5350199e+00,\n",
       "       -1.4319000e+00, -4.7633996e+00,  3.7440000e+00, -1.2749730e+00,\n",
       "        3.1816001e+00,  1.0476298e+00,  1.0784001e+00, -3.0779200e+00,\n",
       "       -1.2711000e+00, -3.6251001e+00, -2.7258501e+00,  4.7676001e+00,\n",
       "        1.5000498e+00,  2.5363998e+00,  9.6959996e-01,  2.8748999e+00,\n",
       "        2.6771998e+00,  1.8741999e+00, -5.3535199e+00,  3.7624002e+00,\n",
       "       -5.4443008e-01, -2.8594000e+00, -2.3983500e+00,  7.5615001e-01,\n",
       "       -1.6862996e+00, -6.4709001e+00,  4.6223898e+00,  4.8498998e+00,\n",
       "       -3.0052018e-01, -3.8868999e+00,  6.3224001e+00, -2.3664501e+00,\n",
       "        2.2703300e+00,  3.3231003e+00, -6.1042299e+00, -5.0201001e+00,\n",
       "        9.5792999e+00,  3.2759299e+00, -2.2653799e+00,  2.1234000e+00,\n",
       "       -4.9017401e+00, -1.7752002e+00, -5.6193900e+00,  4.1918001e+00,\n",
       "       -7.4270792e+00,  4.9396996e+00, -2.4484301e+00,  4.2602000e+00,\n",
       "       -6.5094099e+00,  2.1665001e-01, -4.7990103e+00,  2.1538997e+00,\n",
       "        5.7447004e-01,  4.8984995e+00, -2.2124000e+00,  6.1560011e-01,\n",
       "       -2.9963100e+00, -2.3548698e+00,  3.4073899e+00,  3.2515998e+00,\n",
       "        5.9930038e-01, -4.7820997e+00, -3.5769701e+00,  1.4498850e+00,\n",
       "        3.3627901e+00,  1.6592300e+00, -4.9630995e+00,  3.1173401e+00,\n",
       "       -2.4839001e+00,  6.2902503e+00,  4.9243503e+00,  2.9040699e+00,\n",
       "        4.3234000e+00,  6.6861000e+00,  5.3109980e-01, -2.5485201e+00,\n",
       "        8.3090991e-02, -5.3160200e+00, -1.0756803e+00,  7.8729000e+00,\n",
       "       -4.3389010e-01, -5.2601500e+00,  1.3486199e+01,  2.3806996e+00,\n",
       "       -3.7742000e+00, -1.1628900e+00, -6.5094995e-01, -5.2306204e+00,\n",
       "        3.5393040e+00, -2.8087997e+00,  6.3808994e+00, -4.2631006e+00,\n",
       "       -1.3755180e+00, -1.1459400e+01,  6.9519949e-01, -6.7654104e+00,\n",
       "       -3.7590027e-01,  1.0349000e+00, -7.7567997e+00, -3.3424997e-01,\n",
       "       -2.4899971e-01,  2.7706003e-01, -2.1068301e+00, -4.0296001e+00,\n",
       "       -4.1249003e+00,  9.2911994e-01, -1.9882005e-01, -4.7922001e+00,\n",
       "       -8.0993996e+00,  9.8409986e-01, -2.5156000e+00,  3.9651000e+00,\n",
       "        3.9823101e+00, -1.7520022e-01, -8.5326996e+00,  2.7765503e+00,\n",
       "        5.6943102e+00,  5.4154899e-02, -2.0930729e+00,  3.4601800e+00,\n",
       "        4.3996003e-01,  7.6155643e+00,  4.4245200e+00,  6.7000389e-03,\n",
       "       -2.9654300e+00, -1.4637101e+00, -2.6764998e+00, -4.1227999e+00,\n",
       "       -4.5114298e+00, -7.5515008e+00,  9.1299772e-02, -2.2665730e+00,\n",
       "       -3.1620002e+00, -9.3991003e+00, -8.2884207e+00, -2.1912401e+00,\n",
       "       -2.3130891e+00,  2.6930994e-01,  5.4695005e+00, -4.9580050e-01,\n",
       "       -3.7524998e+00,  1.1632795e+00,  1.5505002e+00, -1.9376998e+00,\n",
       "       -5.0283003e-01, -9.6462005e-01, -1.9391000e+00, -3.0476999e+00,\n",
       "        3.4930000e+00, -8.9099646e-02,  7.2140002e-01, -2.5389199e+00,\n",
       "        4.7689600e+00,  6.6139498e+00, -6.9038987e-01,  1.4298400e+00,\n",
       "        1.9550014e-01,  2.9179108e+00,  1.2519000e+00, -9.3613863e+00,\n",
       "       -5.9127002e+00,  2.1136999e+00,  4.5472403e+00, -1.8481016e-02,\n",
       "       -4.4704199e+00,  1.7130041e-01,  1.0735900e+00,  6.3000903e+00,\n",
       "        6.4400005e-01, -1.0550988e-01, -4.1835999e+00,  4.4136992e-01,\n",
       "       -3.9800000e-01, -4.4532104e+00,  1.6721599e+00,  7.3224001e+00,\n",
       "       -1.0846002e+00,  5.5222998e+00,  3.7199998e-01,  1.2874600e+00,\n",
       "        5.5377903e+00,  6.4842997e+00, -4.4014025e-01,  1.9180198e+00,\n",
       "        5.9175801e+00, -3.3658504e+00,  2.3565402e+00, -6.5751324e+00,\n",
       "       -5.7356200e+00,  3.2288995e+00, -5.7550025e-01,  8.1138000e+00,\n",
       "       -5.8756006e-01, -1.3780003e+00,  5.0790000e-01,  3.6003995e+00,\n",
       "       -2.0974400e+00,  5.4249001e+00,  1.0930002e-01,  1.1624999e+00,\n",
       "       -2.8050101e+00,  6.6023998e+00,  4.0592999e+00,  6.4873004e+00,\n",
       "       -1.6781001e+00, -4.1176033e-01, -4.6373997e+00,  5.2927999e+00,\n",
       "        3.6361998e-01,  1.0570800e+01, -3.6768999e+00, -2.2553000e+00,\n",
       "        1.7148998e+00, -8.5960031e-01,  6.8120003e-01,  4.2570729e+00,\n",
       "        6.0465002e+00,  6.4090991e-01,  2.3524004e-01, -5.4971004e+00,\n",
       "       -7.4195600e+00, -2.9869998e-01,  8.8177013e-01, -8.6038990e+00,\n",
       "        4.4706001e+00,  2.3107004e+00, -5.6815004e-01,  2.5742202e+00,\n",
       "        7.3649991e-01, -1.0553801e+00,  4.1707301e-01,  3.6274299e-01,\n",
       "        2.8873711e+00, -1.9827211e+00, -1.5422699e+00,  1.1284900e+00,\n",
       "       -1.1235000e+01,  5.4754000e+00,  8.1189990e-01, -1.0999300e+00,\n",
       "       -5.9274001e+00, -7.1076298e-01, -1.1008101e+00, -2.2453001e+00,\n",
       "        3.0368700e+00, -3.7698898e+00, -3.7548003e+00,  1.2790999e+00,\n",
       "        9.7320008e-01, -4.2096000e+00,  5.5269995e+00,  1.8465997e+00,\n",
       "        4.0220995e+00,  1.0505199e+00,  2.1808698e+00,  4.7750001e+00,\n",
       "       -3.8340001e+00, -5.8677998e+00,  1.9839001e+00,  2.9614999e+00,\n",
       "       -4.1291223e+00, -1.9792000e+00,  1.5635000e+00,  4.0887995e+00,\n",
       "       -1.3429599e+00, -6.4279995e+00, -7.1104698e+00,  2.1612999e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform cosine similarity\n",
    "king = nlp.vocab[\"king\"].vector\n",
    "man = nlp.vocab[\"man\"].vector\n",
    "woman = nlp.vocab[\"woman\"].vector\n",
    "queen = nlp.vocab[\"queen\"].vector\n",
    "\n",
    "result = king - man + woman\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e44630df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6178014]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity([result], [queen])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06128b7",
   "metadata": {},
   "source": [
    "# Example: Text Classification Using spaCy Word Vectors\n",
    "\n",
    "https://www.youtube.com/watch?v=ibi5hvw6f3g&list=PLeo1K3hjS3uuvuAXhYjV2lMEShq2UYSwX&index=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6bb4cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
       "1  U.S. conservative leader optimistic of common ...  Real\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Fake_Real_Data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a82ef1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9900, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "281cbeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fake    5000\n",
       "Real    4900\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for class imbalance\n",
    "df.label.value_counts()\n",
    "\n",
    "# no class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fa3b934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label  label_num\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake          0\n",
       "1  U.S. conservative leader optimistic of common ...  Real          1\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real          1\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake          0\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real          1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert label into numbers\n",
    "\n",
    "df['label_num'] = df['label'].map({'Fake': 0, 'Real': 1})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e09b290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text column into word vectors\n",
    "# (make new column with each doc's vector)\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c9954a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# takes a long time! :)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn [32], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# takes a long time! :)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvector)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\spacy\\language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\spacy\\pipeline\\tok2vec.py:125\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    123\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m--> 125\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\thinc\\layers\\concatenate.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(OutT, data_l), backprop\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], Ragged):\n\u001b[1;32m---> 54\u001b[0m     data_r, backprop \u001b[38;5;241m=\u001b[39m \u001b[43m_ragged_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(OutT, data_r), backprop\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\thinc\\layers\\concatenate.py:93\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[1;34m(model, X, Ys, callbacks, is_train)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ragged_forward\u001b[39m(\n\u001b[0;32m     89\u001b[0m     model: Model[InT, OutT], X, Ys: List, callbacks, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     90\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[0;32m     92\u001b[0m     widths \u001b[38;5;241m=\u001b[39m [Y\u001b[38;5;241m.\u001b[39mdataXd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m Y \u001b[38;5;129;01min\u001b[39;00m Ys]\n\u001b[1;32m---> 93\u001b[0m     output \u001b[38;5;241m=\u001b[39m Ragged(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mYs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, Ys[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlengths)\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(d_output: Ragged) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InT:\n\u001b[0;32m     96\u001b[0m         d_array \u001b[38;5;241m=\u001b[39m d_output\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\numpy\\core\\shape_base.py:345\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# takes a long time! :)\n",
    "df['vector'] = df['Text'].apply(lambda x: nlp(x).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d55477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.vector.values, # df.vector.values \n",
    "    df.label_num,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = df.label_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52387fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(scaled_train_embed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance on test data\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(scaled_test_embed)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0e4f2",
   "metadata": {},
   "source": [
    "# Gensim Word Vectors\n",
    "\n",
    "https://github.com/codebasics/nlp-tutorials/blob/main/15_word_vectors_gensim_overview/nlp_word_vectors_gensim_overview.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# download model that is trained on google news\n",
    "wv = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# other models available:\n",
    "# twitter, wiki\n",
    "# glove, fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292367e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.similarity(w1 = 'great', w2 = 'good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b41b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.similarity(w1 = 'great', w2 = 'great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca694f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do vector math\n",
    "wv.most_similar(positive = ['france', 'berlin'], negative = ['paris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b68ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(positive = ['king', 'woman'], negative = ['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987392ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(positive = ['puppy', 'adult'], negative = ['young'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f5488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.doesnt_match(['facebook', 'cat', 'google', 'microsoft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.doesnt_match(['dog', 'cat', 'lion', 'google'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model\n",
    "glv = api.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f3214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will give different answers to same math questions\n",
    "glv.most_similar('good')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5829ed8c",
   "metadata": {},
   "source": [
    "# Example: News Classification With Gensim Word Vectors\n",
    "\n",
    "https://www.youtube.com/watch?v=ZrgVlfNduj8&list=PLeo1K3hjS3uuvuAXhYjV2lMEShq2UYSwX&index=23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5861edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ae833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('fake_and_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8afe786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87086b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class imbalance?\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numeric column for label\n",
    "df['label_num'] = df.label.map({'Fake': 0, 'Real': 1})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8940fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess and get gensim doc vector\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def preprocess_and_vectorize(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_punct or token.is_stop:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return wv.get_mean_vector(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "preprocess_and_vectorize(\"No worries if you don't understand!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80417809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text into gensim word embeddings\n",
    "\n",
    "df['gensim_vector'] = df['Text'].apply(lambda text: preprocess_and_vectorize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b946ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2072007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.gensim_vector.values,\n",
    "    df.label_num,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = df.label_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f3d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2d np arrays for X train and test sets\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ccae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60de95f",
   "metadata": {},
   "source": [
    "# fastText\n",
    "\n",
    "https://www.youtube.com/watch?v=Br-Ozg9D4mc&list=PLeo1K3hjS3uuvuAXhYjV2lMEShq2UYSwX&index=24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf0155",
   "metadata": {},
   "source": [
    "**Word2vec:** neural network is trained on individual words (in context)\n",
    "\n",
    "**fastText:** neural network is trained on CHARACTER n GRAM (where n is a hyperparameter; 3-6 are popular)\n",
    "- ex: word 'capable', n = 3\n",
    "- CHARACTER n GRAMS: 'cap', 'apa', 'pab', 'abl', 'ble'\n",
    "- will also include the whole word\n",
    "\n",
    "**Advantage of fastText vs. Word2vec:** Word2vec has out-of-vocabulary problem, where if a word is in the test that wasn't in the train, the model doesn't have a vector for that word (even if it is close to another word it does have, like 'capability' vs. 'capable'). With fastText, the OOV problem is largely dealt with, since, for example, the model will have vectors for n-grams 'cap', 'apa', and 'pab' for both 'capability' and 'capable'. \n",
    "\n",
    "fastText is a technique as well as a library.\n",
    "\n",
    "Often a first choice when you want to train custom word embeddings for your domain. \n",
    "\n",
    "**Potential problem:** getting vectors for 'cap' when it appears in 'capability'/'capable' vs in a different word (like 'cap' as in 'baseball cap') would, correctly, result in different vectors with Word2vec but would be collapsed into the same vector in fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6107d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (0.9.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from fasttext) (2.10.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from fasttext) (1.23.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from fasttext) (65.5.0)\n"
     ]
    }
   ],
   "source": [
    "# pretrained model\n",
    "\n",
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c85a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fasttext' from 'C:\\\\Users\\\\yang0108\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\dojo-env\\\\lib\\\\site-packages\\\\fasttext\\\\__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext\n",
    "fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9177e577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model_en = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0663522d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_labels',\n",
       " '_words',\n",
       " 'f',\n",
       " 'get_analogies',\n",
       " 'get_dimension',\n",
       " 'get_input_matrix',\n",
       " 'get_input_vector',\n",
       " 'get_label_id',\n",
       " 'get_labels',\n",
       " 'get_line',\n",
       " 'get_meter',\n",
       " 'get_nearest_neighbors',\n",
       " 'get_output_matrix',\n",
       " 'get_sentence_vector',\n",
       " 'get_subword_id',\n",
       " 'get_subwords',\n",
       " 'get_word_id',\n",
       " 'get_word_vector',\n",
       " 'get_words',\n",
       " 'is_quantized',\n",
       " 'labels',\n",
       " 'predict',\n",
       " 'quantize',\n",
       " 'save_model',\n",
       " 'set_args',\n",
       " 'set_matrices',\n",
       " 'test',\n",
       " 'test_label',\n",
       " 'words']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31182391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7517593502998352, 'bad'),\n",
       " (0.7426098585128784, 'great'),\n",
       " (0.7299689054489136, 'decent'),\n",
       " (0.7123614549636841, 'nice'),\n",
       " (0.6796907186508179, 'Good'),\n",
       " (0.6737031936645508, 'excellent'),\n",
       " (0.669592022895813, 'goood'),\n",
       " (0.6602178812026978, 'ggod'),\n",
       " (0.6479219794273376, 'semi-good'),\n",
       " (0.6417751908302307, 'good.Good')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.get_nearest_neighbors(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00d510be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09213716, -0.0634383 ,  0.00173813,  0.13524324, -0.06561062,\n",
       "        0.00619071,  0.12609869, -0.01646539,  0.0174491 , -0.00126792,\n",
       "       -0.09709831,  0.02329333,  0.00996784,  0.00463419,  0.01587938,\n",
       "        0.00689824,  0.08575399, -0.01988525, -0.0601579 , -0.02327966,\n",
       "        0.01183712,  0.08217917,  0.01488847,  0.00902181,  0.00696296,\n",
       "       -0.06426616,  0.03345198, -0.02101481,  0.06767873,  0.03022419,\n",
       "        0.07203474, -0.05689922, -0.04370377,  0.00642597,  0.0439174 ,\n",
       "        0.0604848 , -0.00611545, -0.12256738, -0.03530414, -0.02696739,\n",
       "       -0.02058216,  0.00752347, -0.00686451,  0.0362783 , -0.03308735,\n",
       "        0.05801626,  0.00832448, -0.06336953, -0.05775082,  0.01089846,\n",
       "       -0.0925179 ,  0.01559984, -0.04079024,  0.0066871 , -0.06374165,\n",
       "        0.05881973,  0.07209535, -0.05387195, -0.14658651, -0.04046486,\n",
       "       -0.02507038, -0.04954465, -0.05224417, -0.06846938,  0.0467079 ,\n",
       "        0.00459271, -0.07522177,  0.03627685, -0.0698283 ,  0.0174791 ,\n",
       "       -0.03427085, -0.043176  ,  0.00764059,  0.05694873,  0.0064466 ,\n",
       "       -0.01078498,  0.02328758,  0.06951396,  0.05373847,  0.02533235,\n",
       "        0.04307906, -0.03298698, -0.01265992,  0.02883131,  0.01145704,\n",
       "       -0.03029559,  0.02814867,  0.09258693,  0.08908885,  0.21924517,\n",
       "        0.03836972,  0.05020344,  0.13716629, -0.00859585, -0.0113667 ,\n",
       "        0.10641211, -0.07889125,  0.08034115, -0.00441031, -0.04873084,\n",
       "        0.00183913,  0.06675661,  0.00995041,  0.03010932, -0.02987454,\n",
       "        0.02509423, -0.04333989, -0.0059728 , -0.00332469, -0.0522663 ,\n",
       "       -0.03281598,  0.12006998,  0.01166376, -0.03454734,  0.01907663,\n",
       "       -0.01262398, -0.02025696,  0.01866139,  0.05016267,  0.05604192,\n",
       "        0.04971652,  0.03597424, -0.00690809,  0.05734055,  0.05945349,\n",
       "        0.0261135 ,  0.01734888, -0.00711455, -0.1295353 ,  0.01600225,\n",
       "        0.00150194, -0.03631282, -0.00469453,  0.02215887, -0.00699799,\n",
       "       -0.02894606,  0.03908806,  0.0401371 , -0.03941151, -0.02646147,\n",
       "       -0.04718655,  0.02674983,  0.07485171,  0.03144611, -0.07028159,\n",
       "       -0.0424196 , -0.2054326 , -0.09083363, -0.01121964,  0.05520659,\n",
       "       -0.11916859,  0.00788128, -0.13444994, -0.01488061, -0.02091767,\n",
       "        0.09262317,  0.06291065, -0.02200251, -0.03655258,  0.02587264,\n",
       "        0.0447952 , -0.01287306, -0.0350248 , -0.02456109, -0.04746678,\n",
       "        0.00130645,  0.01147217, -0.00531678,  0.11162786,  0.0253936 ,\n",
       "       -0.03638908, -0.05931935, -0.00549408,  0.0074574 , -0.01289796,\n",
       "       -0.0719263 , -0.02486867, -0.04750141,  0.00194147, -0.1141203 ,\n",
       "        0.01648522,  0.05083858, -0.02679086, -0.04766015,  0.00518819,\n",
       "        0.04099732,  0.02709844, -0.06511603, -0.06652133, -0.07979076,\n",
       "        0.0491582 ,  0.05377757,  0.0200878 , -0.03799915, -0.02513728,\n",
       "        0.00410288, -0.04514588, -0.04708159, -0.00559349,  0.13073431,\n",
       "       -0.09549722,  0.16606593,  0.0221815 , -0.05887613, -0.02126267,\n",
       "        0.00425452, -0.05540022, -0.06286709, -0.05455609,  0.11610305,\n",
       "        0.12443443, -0.00741135,  0.01761745, -0.0075937 , -0.05616794,\n",
       "       -0.01676267,  0.07975771, -0.04046471,  0.07211975,  0.13321361,\n",
       "        0.07106   , -0.01443719,  0.02562447,  0.05690589, -0.0090815 ,\n",
       "       -0.00628489,  0.03647495,  0.00689165,  0.04463093,  0.01837448,\n",
       "        0.00218417, -0.02093561,  0.07896647, -0.05610979,  0.02535573,\n",
       "       -0.09674191, -0.03684152,  0.01628419,  0.00908958, -0.06135098,\n",
       "        0.05458912, -0.03850613,  0.03017449, -0.1417458 ,  0.17130415,\n",
       "       -0.05436675, -0.01079106,  0.04692602, -0.02894384, -0.0273016 ,\n",
       "        0.09735578, -0.13424474, -0.02024667, -0.04736632, -0.03244197,\n",
       "        0.00541304, -0.04343438, -0.0003211 ,  0.16816942,  0.03105447,\n",
       "       -0.03063404, -0.00045107,  0.04690041,  0.11270425, -0.13718411,\n",
       "        0.05740229,  0.00801181, -0.17329559,  0.03051268, -0.1268264 ,\n",
       "       -0.06074513, -0.03838078, -0.01737073,  0.12296247, -0.05316308,\n",
       "       -0.07613882,  0.02129988,  0.0121702 , -0.01287838,  0.0768657 ,\n",
       "       -0.26769733,  0.05321693, -0.12607867, -0.02812696,  0.07982896,\n",
       "       -0.02915069, -0.01767069, -0.10350563, -0.0471432 , -0.03033449,\n",
       "        0.08542065,  0.02928957, -0.11185424, -0.00142424,  0.0379483 ,\n",
       "        0.02438426, -0.01398861,  0.14165413, -0.05115522, -0.08859383],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.get_word_vector(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f28f62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.get_word_vector(\"good\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2e99ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7148876190185547, 'delhi'),\n",
       " (0.6974374055862427, 'mumbai'),\n",
       " (0.648612916469574, 'jaipur'),\n",
       " (0.6349966526031494, 'kolkata'),\n",
       " (0.6279922723770142, 'pune'),\n",
       " (0.6277596354484558, 'bangalore'),\n",
       " (0.6044078469276428, 'hyderabad'),\n",
       " (0.6021745800971985, 'noida'),\n",
       " (0.6018899083137512, 'bhubaneswar'),\n",
       " (0.599077582359314, 'nashik')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.get_analogies(\"berlin\", \"germany\", \"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ef1676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.610385537147522, 'texting'),\n",
       " (0.5203558802604675, 'phone-calling'),\n",
       " (0.5153835415840149, 'cellphone'),\n",
       " (0.5135326981544495, 'cell-phone'),\n",
       " (0.5117910504341125, 'dialing'),\n",
       " (0.5087355971336365, 'texing'),\n",
       " (0.5079342722892761, 'text-messaging'),\n",
       " (0.500900387763977, 'txting'),\n",
       " (0.4960441589355469, 'texting.'),\n",
       " (0.4951859414577484, 'Texting')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.get_analogies(\"driving\", \"car\", \"phone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b0d4d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5302355885505676, 'reading'),\n",
       " (0.517051637172699, 'book.I'),\n",
       " (0.5137901306152344, 'book--and'),\n",
       " (0.5090512633323669, 'book.That'),\n",
       " (0.5005884766578674, 'book--it'),\n",
       " (0.49395182728767395, 'book--I'),\n",
       " (0.49293914437294006, 're-reading'),\n",
       " (0.49156999588012695, 'book.This'),\n",
       " (0.49107635021209717, 'reading--and'),\n",
       " (0.48960915207862854, 'book--the')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.get_analogies(\"driving\", \"car\", \"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14670fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model on your own dataset\n",
    "\n",
    "# indian food dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Cleaned_Indian_Food_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2761f055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TranslatedRecipeName</th>\n",
       "      <th>TranslatedIngredients</th>\n",
       "      <th>TotalTimeInMins</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>TranslatedInstructions</th>\n",
       "      <th>URL</th>\n",
       "      <th>Cleaned-Ingredients</th>\n",
       "      <th>image-url</th>\n",
       "      <th>Ingredient-count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Masala Karela Recipe</td>\n",
       "      <td>1 tablespoon Red Chilli powder,3 tablespoon Gr...</td>\n",
       "      <td>45</td>\n",
       "      <td>Indian</td>\n",
       "      <td>To begin making the Masala Karela Recipe,de-se...</td>\n",
       "      <td>https://www.archanaskitchen.com/masala-karela-...</td>\n",
       "      <td>salt,amchur (dry mango powder),karela (bitter ...</td>\n",
       "      <td>https://www.archanaskitchen.com/images/archana...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spicy Tomato Rice (Recipe)</td>\n",
       "      <td>2 teaspoon cashew - or peanuts, 1/2 Teaspoon ...</td>\n",
       "      <td>15</td>\n",
       "      <td>South Indian Recipes</td>\n",
       "      <td>To make tomato puliogere, first cut the tomato...</td>\n",
       "      <td>https://www.archanaskitchen.com/spicy-tomato-r...</td>\n",
       "      <td>tomato,salt,chickpea lentils,green chilli,rice...</td>\n",
       "      <td>https://www.archanaskitchen.com/images/archana...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ragi Semiya Upma Recipe - Ragi Millet Vermicel...</td>\n",
       "      <td>1 Onion - sliced,1 teaspoon White Urad Dal (Sp...</td>\n",
       "      <td>50</td>\n",
       "      <td>South Indian Recipes</td>\n",
       "      <td>To begin making the Ragi Vermicelli Recipe, fi...</td>\n",
       "      <td>https://www.archanaskitchen.com/ragi-vermicell...</td>\n",
       "      <td>salt,rice vermicelli noodles (thin),asafoetida...</td>\n",
       "      <td>https://www.archanaskitchen.com/images/archana...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gongura Chicken Curry Recipe - Andhra Style Go...</td>\n",
       "      <td>1/2 teaspoon Turmeric powder (Haldi),1 tablesp...</td>\n",
       "      <td>45</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>To begin making Gongura Chicken Curry Recipe f...</td>\n",
       "      <td>https://www.archanaskitchen.com/gongura-chicke...</td>\n",
       "      <td>tomato,salt,ginger,sorrel leaves (gongura),fen...</td>\n",
       "      <td>https://www.archanaskitchen.com/images/archana...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andhra Style Alam Pachadi Recipe - Adrak Chutn...</td>\n",
       "      <td>oil - as per use, 1 tablespoon coriander seed...</td>\n",
       "      <td>30</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>To make Andhra Style Alam Pachadi, first heat ...</td>\n",
       "      <td>https://www.archanaskitchen.com/andhra-style-a...</td>\n",
       "      <td>tomato,salt,ginger,red chillies,curry,asafoeti...</td>\n",
       "      <td>https://www.archanaskitchen.com/images/archana...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                TranslatedRecipeName  \\\n",
       "0                               Masala Karela Recipe   \n",
       "1                         Spicy Tomato Rice (Recipe)   \n",
       "2  Ragi Semiya Upma Recipe - Ragi Millet Vermicel...   \n",
       "3  Gongura Chicken Curry Recipe - Andhra Style Go...   \n",
       "4  Andhra Style Alam Pachadi Recipe - Adrak Chutn...   \n",
       "\n",
       "                               TranslatedIngredients  TotalTimeInMins  \\\n",
       "0  1 tablespoon Red Chilli powder,3 tablespoon Gr...               45   \n",
       "1   2 teaspoon cashew - or peanuts, 1/2 Teaspoon ...               15   \n",
       "2  1 Onion - sliced,1 teaspoon White Urad Dal (Sp...               50   \n",
       "3  1/2 teaspoon Turmeric powder (Haldi),1 tablesp...               45   \n",
       "4   oil - as per use, 1 tablespoon coriander seed...               30   \n",
       "\n",
       "                Cuisine                             TranslatedInstructions  \\\n",
       "0                Indian  To begin making the Masala Karela Recipe,de-se...   \n",
       "1  South Indian Recipes  To make tomato puliogere, first cut the tomato...   \n",
       "2  South Indian Recipes  To begin making the Ragi Vermicelli Recipe, fi...   \n",
       "3                Andhra  To begin making Gongura Chicken Curry Recipe f...   \n",
       "4                Andhra  To make Andhra Style Alam Pachadi, first heat ...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.archanaskitchen.com/masala-karela-...   \n",
       "1  https://www.archanaskitchen.com/spicy-tomato-r...   \n",
       "2  https://www.archanaskitchen.com/ragi-vermicell...   \n",
       "3  https://www.archanaskitchen.com/gongura-chicke...   \n",
       "4  https://www.archanaskitchen.com/andhra-style-a...   \n",
       "\n",
       "                                 Cleaned-Ingredients  \\\n",
       "0  salt,amchur (dry mango powder),karela (bitter ...   \n",
       "1  tomato,salt,chickpea lentils,green chilli,rice...   \n",
       "2  salt,rice vermicelli noodles (thin),asafoetida...   \n",
       "3  tomato,salt,ginger,sorrel leaves (gongura),fen...   \n",
       "4  tomato,salt,ginger,red chillies,curry,asafoeti...   \n",
       "\n",
       "                                           image-url  Ingredient-count  \n",
       "0  https://www.archanaskitchen.com/images/archana...                10  \n",
       "1  https://www.archanaskitchen.com/images/archana...                12  \n",
       "2  https://www.archanaskitchen.com/images/archana...                12  \n",
       "3  https://www.archanaskitchen.com/images/archana...                15  \n",
       "4  https://www.archanaskitchen.com/images/archana...                12  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e63370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 'TranslatedInstructions' column to train model\n",
    "# clean dataset: remove special characters, etc. with regex\n",
    "# regex101.com\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e556e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To begin making the Masala Karela Recipe,de-seed the karela and slice.\\nDo not remove the skin as the skin has all the nutrients.\\nAdd the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\\nRelease the pressure immediately and open the lids.\\nKeep aside.Heat oil in a heavy bottomed pan or a kadhai.\\nAdd cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\\nStir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\\nTurn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use one row's text to practice in regex101.com\n",
    "text = df['TranslatedInstructions'][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2c71c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To begin making the Masala Karela Recipe de seed the karela and slice \\nDo not remove the skin as the skin has all the nutrients \\nAdd the karela to the pressure cooker with 3 tablespoon of water  salt and turmeric powder and pressure cook for three whistles \\nRelease the pressure immediately and open the lids \\nKeep aside Heat oil in a heavy bottomed pan or a kadhai \\nAdd cumin seeds and let it sizzle Once the cumin seeds have sizzled  add onions and saute them till it turns golden brown in color Add the karela  red chilli powder  amchur powder  coriander powder and besan \\nStir to combine the masalas into the karela Drizzle a little extra oil on the top and mix again \\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well \\nTurn off the heat Transfer Masala Karela into a serving bowl and serve Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# substitute any non-alphanumeric chracter with a space\n",
    "\n",
    "text = re.sub(r'[^\\w\\s]', ' ', text, flags = re.MULTILINE)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "115d4ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To begin making the Masala Karela Recipe de seed the karela and slice  Do not remove the skin as the skin has all the nutrients  Add the karela to the pressure cooker with 3 tablespoon of water  salt and turmeric powder and pressure cook for three whistles  Release the pressure immediately and open the lids  Keep aside Heat oil in a heavy bottomed pan or a kadhai  Add cumin seeds and let it sizzle Once the cumin seeds have sizzled  add onions and saute them till it turns golden brown in color Add the karela  red chilli powder  amchur powder  coriander powder and besan  Stir to combine the masalas into the karela Drizzle a little extra oil on the top and mix again  Cover the pan and simmer Masala Karela stirring occasionally until everything comes together well  Turn off the heat Transfer Masala Karela into a serving bowl and serve Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family  '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove newline characters\n",
    "text = re.sub(r\"\\n\", \" \", text, flags = re.MULTILINE)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cd959c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To begin making the Masala Karela Recipe de seed the karela and slice Do not remove the skin as the skin has all the nutrients Add the karela to the pressure cooker with 3 tablespoon of water salt and turmeric powder and pressure cook for three whistles Release the pressure immediately and open the lids Keep aside Heat oil in a heavy bottomed pan or a kadhai Add cumin seeds and let it sizzle Once the cumin seeds have sizzled add onions and saute them till it turns golden brown in color Add the karela red chilli powder amchur powder coriander powder and besan Stir to combine the masalas into the karela Drizzle a little extra oil on the top and mix again Cover the pan and simmer Masala Karela stirring occasionally until everything comes together well Turn off the heat Transfer Masala Karela into a serving bowl and serve Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove extra spaces\n",
    "text = re.sub(r\" {2,}\", \" \", text, flags = re.MULTILINE)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d769ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all these steps into a preprocessing function\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"[^\\w\\w\\\"]\", \" \", text)\n",
    "    text = re.sub(r\"[ \\n]+\", \" \", text)\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc9dbec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make tomato puliogere, first cut the tomatoes.\\nNow put in a mixer grinder and puree it.\\nNow heat oil in a pan.\\nAfter the oil is hot, add chana dal, urad dal, cashew and let it cook for 10 to 20 seconds.\\nAfter 10 to 20 seconds, add cumin seeds, mustard seeds, green chillies, dry red chillies and curry leaves.\\nAfter 30 seconds, add tomato puree to it and mix.\\nAdd BC Belle Bhat powder, salt and mix it.\\nAllow to cook for 7 to 8 minutes and then turn off the gas.\\nTake it out in a bowl, add cooked rice and mix it.\\nServe hot.\\nServe tomato puliogre with tomato cucumber raita and papad for dinner.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['TranslatedInstructions'][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2605e0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to make tomato puliogere first cut the tomatoes now put in a mixer grinder and puree it now heat oil in a pan after the oil is hot add chana dal urad dal cashew and let it cook for 10 to 20 seconds after 10 to 20 seconds add cumin seeds mustard seeds green chillies dry red chillies and curry leaves after 30 seconds add tomato puree to it and mix add bc belle bhat powder salt and mix it allow to cook for 7 to 8 minutes and then turn off the gas take it out in a bowl add cooked rice and mix it serve hot serve tomato puliogre with tomato cucumber raita and papad for dinner'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3697bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to entire column\n",
    "df['TranslatedInstructions'] = df['TranslatedInstructions'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "250a6a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to begin making the ragi vermicelli recipe first steam the ragi vermicelli in a rice cooker or a steamer for about 5 6 minutes or till it is cooked but firm keep aside this aside till later use you can add a few drops of oil and mix it so that they don t stick to each other place a kadai on the heat add the ghee or oil to it and when warm add hing and allow it to sizzle for 30 seconds then follow it up with mustard seeds urad dal and curry leaves and allow them to crackle saute for 1 minute or so till the urad dal is slightly browned then add onions and fry till translucent and soft next add the green chillies along with par boiled carrots and peas sprinkle some salt and cook for 2 3 minutes or until the vegetables are semi cooked then add the steamed ragi vermicelli toss it together so the vegetables are all well combined switch off the heat take the vermicelli out into a serving dish and to with lemon juice mix well and serve along with coconut chutney and a hot cup of coffee or tea for a wholesome breakfast'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TranslatedInstructions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6dc58cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data to csv to train model\n",
    "df.to_csv(\"food_recipes.txt\", \n",
    "          columns = ['TranslatedInstructions'], \n",
    "          header = None, \n",
    "          index = False)\n",
    "\n",
    "# every line is a recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d65d8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train fasttext model on text\n",
    "model = fasttext.train_unsupervised(\"food_recipes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e59b1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5873678922653198, 'give'),\n",
       " (0.5548170804977417, 'retained'),\n",
       " (0.5144150853157043, 'goodness'),\n",
       " (0.5059404969215393, '70'),\n",
       " (0.5023975968360901, 'got'),\n",
       " (0.4985058903694153, 'attained'),\n",
       " (0.48711153864860535, 'amchoor'),\n",
       " (0.4862218201160431, 'condiments'),\n",
       " (0.48579737544059753, 'well'),\n",
       " (0.48556724190711975, 'bright')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now model has different word vectors than pre-trained models\n",
    "model.get_nearest_neighbors(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6388af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this default method uses skipgrams, but you can use cbow instead\n",
    "# model = fasttext.train_unsupervised(\"text\", \"cbow\")\n",
    "# hyperparameter tuning: change dimensions of word vectors (default is 100),\n",
    "# number of epochs (default is 5)\n",
    "# more info: https://fasttext.cc/docs/en/unsupervised-tutorial.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4011e87",
   "metadata": {},
   "source": [
    "# Example: Text Classification Using fastText\n",
    "\n",
    "https://www.youtube.com/watch?v=Cq_pbQYO3M8&list=PLeo1K3hjS3uuvuAXhYjV2lMEShq2UYSwX&index=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4b336e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                        description\n",
       "0  Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1  Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2  Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3  Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4  Household  Incredible Gifts India Wooden Happy Birthday U..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ecommerce_dataset.csv\", \n",
    "                 names = ['category', 'description'], \n",
    "                 header = None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a28383b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50425, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e49c497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Household                 19313\n",
       "Books                     11820\n",
       "Electronics               10621\n",
       "Clothing & Accessories     8671\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf7cdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category       0\n",
       "description    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be59756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7dcc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category       0\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb1910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace category names with spaces to not have spaces\n",
    "df.category.replace(\"Clothing & Accessories\", \"Clothing_Accessories\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "000f9f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Household', 'Books', 'Clothing_Accessories', 'Electronics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa74a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext expects the format of text as follows:\n",
    "# one text per line\n",
    "# label (one string, no spaces) at beginning of line, followed by a space,\n",
    "# followed by the text\n",
    "# if there is more than one label for the text, it can go after the first label\n",
    "# and a space\n",
    "# the label must have the string \"__label__\" prefixed\n",
    "\n",
    "# prefix \"__label__\" to all categories\n",
    "df['category'] = \"__label__\" + df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4655fad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['__label__Household', '__label__Books',\n",
       "       '__label__Clothing_Accessories', '__label__Electronics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "\n",
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d01991fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>category_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "      <td>__label__Household Paper Plane Design Framed W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "      <td>__label__Household SAF 'Floral' Framed Paintin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "      <td>__label__Household SAF 'UV Textured Modern Art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "      <td>__label__Household SAF Flower Print Framed Pai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "      <td>__label__Household Incredible Gifts India Wood...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                        description  \\\n",
       "0  __label__Household  Paper Plane Design Framed Wall Hanging Motivat...   \n",
       "1  __label__Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...   \n",
       "2  __label__Household  SAF 'UV Textured Modern Art Print Framed' Pain...   \n",
       "3  __label__Household  SAF Flower Print Framed Painting (Synthetic, 1...   \n",
       "4  __label__Household  Incredible Gifts India Wooden Happy Birthday U...   \n",
       "\n",
       "                                category_description  \n",
       "0  __label__Household Paper Plane Design Framed W...  \n",
       "1  __label__Household SAF 'Floral' Framed Paintin...  \n",
       "2  __label__Household SAF 'UV Textured Modern Art...  \n",
       "3  __label__Household SAF Flower Print Framed Pai...  \n",
       "4  __label__Household Incredible Gifts India Wood...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two columns so the text is on the same line as the label\n",
    "df['category_description'] = df['category'] + \" \" + df['description']\n",
    "\n",
    "# check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc812c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  VIKI's   Bookcase Bookshelf  3 Shelf Shelve  White        hi\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommended to preprocess by converting to lower, removing punctuation,\n",
    "# removing extra white spaces, etc.\n",
    "\n",
    "# preprocess with re (regex101.com)\n",
    "\n",
    "import re\n",
    "\n",
    "text = \"  VIKI's | Bookcase/Bookshelf (3-Shelf/Shelve, White) | ? . hi\"\n",
    "\n",
    "# sub all non-word characters except apostrophe with space\n",
    "text = re.sub(r\"[^\\w\\s\\']\", \" \", text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0aa6cf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" VIKI's Bookcase Bookshelf 3 Shelf Shelve White hi\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sub multiple spaces with one space\n",
    "text = re.sub(r\" +\", \" \", text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "497985a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"viki's bookcase bookshelf 3 shelf shelve white hi\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.strip().lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b2671b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it all into a function\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"[^\\w\\s\\']\", \" \", text)\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "379225ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"viki's bookcase bookshelf 3 shelf shelve white hi\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "text = \"  VIKI's | Bookcase/Bookshelf (3-Shelf/Shelve, White) | ? . hi\"\n",
    "\n",
    "preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "919749aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>category_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "      <td>__label__household paper plane design framed w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "      <td>__label__household saf 'floral' framed paintin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "      <td>__label__household saf 'uv textured modern art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "      <td>__label__household saf flower print framed pai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "      <td>__label__household incredible gifts india wood...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                        description  \\\n",
       "0  __label__Household  Paper Plane Design Framed Wall Hanging Motivat...   \n",
       "1  __label__Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...   \n",
       "2  __label__Household  SAF 'UV Textured Modern Art Print Framed' Pain...   \n",
       "3  __label__Household  SAF Flower Print Framed Painting (Synthetic, 1...   \n",
       "4  __label__Household  Incredible Gifts India Wooden Happy Birthday U...   \n",
       "\n",
       "                                category_description  \n",
       "0  __label__household paper plane design framed w...  \n",
       "1  __label__household saf 'floral' framed paintin...  \n",
       "2  __label__household saf 'uv textured modern art...  \n",
       "3  __label__household saf flower print framed pai...  \n",
       "4  __label__household incredible gifts india wood...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess on entire category_description column\n",
    "df['category_description'] = df['category_description'].map(preprocess)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0fb9106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, \n",
    "                               test_size = 0.2, \n",
    "                               stratify = df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d498bbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40339, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2af6d648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10085, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c391ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>category_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27643</th>\n",
       "      <td>__label__Books</td>\n",
       "      <td>How to Think Like a Writer: A Short Book for C...</td>\n",
       "      <td>__label__books how to think like a writer a sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30244</th>\n",
       "      <td>__label__Books</td>\n",
       "      <td>Archaeology: Theories, Methods and Practice Re...</td>\n",
       "      <td>__label__books archaeology theories methods an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32499</th>\n",
       "      <td>__label__Clothing_Accessories</td>\n",
       "      <td>Littly Khadi Style Ethnic Wear Kids Cotton Kur...</td>\n",
       "      <td>__label__clothing_accessories littly khadi sty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10430</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>R Crafts Handmade Wooden Non-Stick Serving And...</td>\n",
       "      <td>__label__household r crafts handmade wooden no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13183</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>JAPP ABS Multifunction EU Plug Electric Steame...</td>\n",
       "      <td>__label__household japp abs multifunction eu p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            category  \\\n",
       "27643                 __label__Books   \n",
       "30244                 __label__Books   \n",
       "32499  __label__Clothing_Accessories   \n",
       "10430             __label__Household   \n",
       "13183             __label__Household   \n",
       "\n",
       "                                             description  \\\n",
       "27643  How to Think Like a Writer: A Short Book for C...   \n",
       "30244  Archaeology: Theories, Methods and Practice Re...   \n",
       "32499  Littly Khadi Style Ethnic Wear Kids Cotton Kur...   \n",
       "10430  R Crafts Handmade Wooden Non-Stick Serving And...   \n",
       "13183  JAPP ABS Multifunction EU Plug Electric Steame...   \n",
       "\n",
       "                                    category_description  \n",
       "27643  __label__books how to think like a writer a sh...  \n",
       "30244  __label__books archaeology theories methods an...  \n",
       "32499  __label__clothing_accessories littly khadi sty...  \n",
       "10430  __label__household r crafts handmade wooden no...  \n",
       "13183  __label__household japp abs multifunction eu p...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f0ac293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__Household               0.383004\n",
       "__label__Books                   0.234413\n",
       "__label__Electronics             0.210640\n",
       "__label__Clothing_Accessories    0.171943\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.category.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "729ccb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>category_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18536</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>What the Dog Saw: And Other Adventures About t...</td>\n",
       "      <td>__label__household what the dog saw and other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21702</th>\n",
       "      <td>__label__Books</td>\n",
       "      <td>Chapterwise Solved Papers Chemistry GATE 2019 ...</td>\n",
       "      <td>__label__books chapterwise solved papers chemi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6241</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>Gala Spin Mop Rod (Compatible with only Gala m...</td>\n",
       "      <td>__label__household gala spin mop rod compatibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17839</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>Cera Cloister 1046 Wash Basin (White , One Pie...</td>\n",
       "      <td>__label__household cera cloister 1046 wash bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>__label__Household</td>\n",
       "      <td>EZ Life Kitchen Roll Dispenser - Towel Holder ...</td>\n",
       "      <td>__label__household ez life kitchen roll dispen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category                                        description  \\\n",
       "18536  __label__Household  What the Dog Saw: And Other Adventures About t...   \n",
       "21702      __label__Books  Chapterwise Solved Papers Chemistry GATE 2019 ...   \n",
       "6241   __label__Household  Gala Spin Mop Rod (Compatible with only Gala m...   \n",
       "17839  __label__Household  Cera Cloister 1046 Wash Basin (White , One Pie...   \n",
       "9985   __label__Household  EZ Life Kitchen Roll Dispenser - Towel Holder ...   \n",
       "\n",
       "                                    category_description  \n",
       "18536  __label__household what the dog saw and other ...  \n",
       "21702  __label__books chapterwise solved papers chemi...  \n",
       "6241   __label__household gala spin mop rod compatibl...  \n",
       "17839  __label__household cera cloister 1046 wash bas...  \n",
       "9985   __label__household ez life kitchen roll dispen...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3ab78c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__Household               0.383044\n",
       "__label__Books                   0.234408\n",
       "__label__Electronics             0.210610\n",
       "__label__Clothing_Accessories    0.171939\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.category.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2eb7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save category_description column in file for fasttext to read\n",
    "train.to_csv(\"ecommerce_train\", \n",
    "             columns = [\"category_description\"], \n",
    "             index = False, \n",
    "             header = False)\n",
    "\n",
    "test.to_csv(\"ecommerce_test\", \n",
    "             columns = [\"category_description\"], \n",
    "             index = False, \n",
    "             header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b601f2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10083, 0.9686601209957354, 0.9686601209957354)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "# supervised method is used to do text classification\n",
    "# unsupervised technique from previous tutorial is used to generate word embeddings\n",
    "\n",
    "# the supervised model will first get trained on your data to generate word\n",
    "# embeddings, then will use those word embeddings for classification\n",
    "\n",
    "model = fasttext.train_supervised(input = 'ecommerce_train')\n",
    "model.test(\"ecommerce_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb4418fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9979151487350464, 'colour'),\n",
       " (0.9975535273551941, 'tripod'),\n",
       " (0.9973239898681641, 'laptops'),\n",
       " (0.997262179851532, 'whey'),\n",
       " (0.9971546530723572, 'gen'),\n",
       " (0.9969862103462219, 'link'),\n",
       " (0.996778130531311, 'mac'),\n",
       " (0.9967317581176758, 'glossy'),\n",
       " (0.9966189861297607, 'connectivity'),\n",
       " (0.9963929057121277, 'gps')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first number is size of test samples\n",
    "# second is precision\n",
    "# third is recall\n",
    "\n",
    "# can predict new texts with:\n",
    "# model.predict(\"TEXT HERE\")\n",
    "\n",
    "# the model has been trained, so it has word embeddings\n",
    "model.get_nearest_neighbors(\"sony\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887cbeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
