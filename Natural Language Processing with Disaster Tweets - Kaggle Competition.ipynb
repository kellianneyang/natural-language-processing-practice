{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81565380",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Natural Language Processing with Disaster Tweets (Kaggle Competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64dd07cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f88263",
   "metadata": {},
   "source": [
    "# Starter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d003ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb817cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "train_df = pd.read_csv(\"Data/train.csv\")\n",
    "test_df = pd.read_csv(\"Data/test.csv\")\n",
    "\n",
    "# check\n",
    "train_df.info()\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cabfb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a691924a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class balance\n",
    "train_df['target'].value_counts()\n",
    "\n",
    "# the classes are a bit unbalanced (57% to 43%),\n",
    "# so we may want to try some class balancing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0284d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check uniqueness of id column\n",
    "train_df['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548a660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love fruits\n",
      "Summer is lovely\n",
      "My car is so fast\n",
      "What a goooooooaaaaaal!!!!!!\n",
      "this is ridiculous....\n",
      "London is cool ;)\n",
      "Love skiing\n",
      "What a wonderful day!\n",
      "LOOOOOOL\n"
     ]
    }
   ],
   "source": [
    "# check examples of non-disaster tweets (target = 0)\n",
    "nondisaster_df = train_df[train_df['target'] == 0]\n",
    "\n",
    "for tweet in nondisaster_df['text'].values[1:10]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1f8959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest fire near La Ronge Sask. Canada\n",
      "All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
      "13,000 people receive #wildfires evacuation orders in California \n",
      "Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n",
      "#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires\n",
      "#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas\n",
      "I'm on top of the hill and I can see a fire in the woods...\n",
      "There's an emergency evacuation happening now in the building across the street\n",
      "I'm afraid that the tornado is coming to our area...\n"
     ]
    }
   ],
   "source": [
    "# check examples of disaster tweets (target = 1)\n",
    "disaster_df = train_df[train_df['target'] == 1]\n",
    "\n",
    "for tweet in disaster_df['text'].values[1:10]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f150652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 54)\n",
      "[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# count the words in each tweet and turn them into word vectors\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "# check\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df['text'][0:5])\n",
    "print(example_train_vectors[0].todense().shape)\n",
    "print(example_train_vectors[0].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3724da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all vectors\n",
    "train_vectors = count_vectorizer.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a554428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model: linear ridge regression\n",
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c06a17d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59453669, 0.5642787 , 0.64117647])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get f1 score of baseline model\n",
    "scores = model_selection.cross_val_score(clf, \n",
    "                                         train_vectors, \n",
    "                                         train_df['target'], \n",
    "                                         cv = 3, \n",
    "                                         scoring = 'f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025c4189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       869\n",
      "           1       0.77      0.68      0.72       654\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.78      0.76      0.77      1523\n",
      "weighted avg       0.78      0.78      0.77      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.text,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('count_vectorizer', feature_extraction.text.CountVectorizer()),\n",
    "    ('ridge_classifier', linear_model.RidgeClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c01ee040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to save scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scores_df = pd.DataFrame()\n",
    "\n",
    "def save_scores(model_pipe, X_train, X_test, y_train, y_test, name):\n",
    "  \n",
    "    # calculate predictions\n",
    "    train_pred = model_pipe.predict(X_train)\n",
    "    test_pred = model_pipe.predict(X_test)\n",
    "    \n",
    "    # save f1 scores for each class\n",
    "    f1_train_scores = f1_score(y_train, train_pred, average = None)\n",
    "    for i, f1 in enumerate(f1_train_scores):\n",
    "        if i == 0:\n",
    "            f1_0_train = f1\n",
    "        elif i == 1:\n",
    "            f1_1_train = f1\n",
    "            \n",
    "    f1_test_scores = f1_score(y_test, test_pred, average = None)\n",
    "    for i, f1 in enumerate(f1_test_scores):\n",
    "        if i == 0:\n",
    "            f1_0_test = f1\n",
    "        elif i == 1:\n",
    "            f1_1_test = f1\n",
    "        \n",
    "    # store scores\n",
    "    scores_df.at[name, 'F1_0_Train'] = f1_0_train\n",
    "    scores_df.at[name, 'F1_1_Train'] = f1_1_train\n",
    "    scores_df.at[name, 'F1_Avg_Train'] = f1_score(y_train, train_pred, average = 'macro')\n",
    "    scores_df.at[name, 'F1_0_Test'] = f1_0_test\n",
    "    scores_df.at[name, 'F1_1_Test'] = f1_1_test\n",
    "    scores_df.at[name, 'F1_Avg_Test'] = f1_score(y_test, test_pred, average = 'macro')\n",
    "    \n",
    "    # show scores for this model only (can call scores_df to see all scores)\n",
    "    print(scores_df.loc[name, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d73c0",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127fa007",
   "metadata": {},
   "source": [
    "## No class balancing, no preprocessing (KNN, MNB, RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b723be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42164b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts on unprocessed data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.text,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c989ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       869\n",
      "           1       0.77      0.65      0.71       654\n",
      "\n",
      "    accuracy                           0.77      1523\n",
      "   macro avg       0.77      0.75      0.76      1523\n",
      "weighted avg       0.77      0.77      0.76      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# knn, tfidf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1631d7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.865827\n",
      "F1_1_Train      0.799016\n",
      "F1_Avg_Train    0.832421\n",
      "F1_0_Test       0.808234\n",
      "F1_1_Test       0.705000\n",
      "F1_Avg_Test     0.756617\n",
      "Name: knn-tfidf-unb, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"knn-tfidf-unb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d828f5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  F1_1_Test  \\\n",
       "knn-tfidf-unb    0.865827    0.799016      0.832421   0.808234      0.705   \n",
       "\n",
       "               F1_Avg_Test  \n",
       "knn-tfidf-unb     0.756617  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9604b545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84       869\n",
      "           1       0.87      0.61      0.72       654\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.81      0.77      0.78      1523\n",
      "weighted avg       0.81      0.79      0.78      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multinomial naive bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c35df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.910580\n",
      "F1_1_Train      0.859256\n",
      "F1_Avg_Train    0.884918\n",
      "F1_0_Test       0.835836\n",
      "F1_1_Test       0.715695\n",
      "F1_Avg_Test     0.775766\n",
      "Name: mnb-tfidf-unb, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-unb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9190d84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82       869\n",
      "           1       0.84      0.56      0.67       654\n",
      "\n",
      "    accuracy                           0.76      1523\n",
      "   macro avg       0.79      0.74      0.74      1523\n",
      "weighted avg       0.78      0.76      0.75      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('Random Forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4df9d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.997409\n",
      "F1_1_Train      0.996561\n",
      "F1_Avg_Train    0.996985\n",
      "F1_0_Test       0.816786\n",
      "F1_1_Test       0.672161\n",
      "F1_Avg_Test     0.744474\n",
      "Name: rf-tfidf-unb, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"rf-tfidf-unb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63d7c2",
   "metadata": {},
   "source": [
    "## No class balancing, minimal preprocessing (KNN, MNB, RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df221a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing: removing spacy stopwords and punctuation, lemmatizing\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # take out stopwords and punctuation\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        \n",
    "        # convert to lemmas\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "            \n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90c1e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['preprocessed_txt'] = train_df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7486344f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed Reason earthquake ALLAH forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near La Ronge Sask Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive wildfire evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo Ruby Alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                   preprocessed_txt  \n",
       "0       1               deed Reason earthquake ALLAH forgive  \n",
       "1       1              forest fire near La Ronge Sask Canada  \n",
       "2       1  resident ask shelter place notify officer evac...  \n",
       "3       1  13,000 people receive wildfire evacuation orde...  \n",
       "4       1  got send photo Ruby Alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c67399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts on processed data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.preprocessed_txt,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c92599d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       869\n",
      "           1       0.77      0.63      0.70       654\n",
      "\n",
      "    accuracy                           0.76      1523\n",
      "   macro avg       0.77      0.75      0.75      1523\n",
      "weighted avg       0.76      0.76      0.76      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# knn on preprocessed data\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40caf7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.865442\n",
      "F1_1_Train      0.791545\n",
      "F1_Avg_Train    0.828493\n",
      "F1_0_Test       0.805391\n",
      "F1_1_Test       0.696893\n",
      "F1_Avg_Test     0.751142\n",
      "Name: knn-tfidf-unb-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"knn-tfidf-unb-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4252b8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       869\n",
      "           1       0.84      0.65      0.73       654\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.78      0.78      1523\n",
      "weighted avg       0.80      0.80      0.79      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multinomial naive bayes on preprocessed text\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f260cd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.926736\n",
      "F1_1_Train      0.889803\n",
      "F1_Avg_Train    0.908269\n",
      "F1_0_Test       0.836074\n",
      "F1_1_Test       0.733850\n",
      "F1_Avg_Test     0.784962\n",
      "Name: mnb-tfidf-unb-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-unb-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a3cccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       869\n",
      "           1       0.85      0.59      0.70       654\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.80      0.76      0.76      1523\n",
      "weighted avg       0.79      0.78      0.77      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest on preprocessed text\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('Random Forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b286be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.997554\n",
      "F1_1_Train      0.996749\n",
      "F1_Avg_Train    0.997152\n",
      "F1_0_Test       0.826873\n",
      "F1_1_Test       0.698470\n",
      "F1_Avg_Test     0.762672\n",
      "Name: rf-tfidf-unb-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"rf-tfidf-unb-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b67c5204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996749</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.762672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb-prep</th>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.816786</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.744474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep    0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb         0.910580    0.859256      0.884918   0.835836   \n",
       "rf-tfidf-unb-prep     0.997554    0.996749      0.997152   0.826873   \n",
       "knn-tfidf-unb         0.865827    0.799016      0.832421   0.808234   \n",
       "knn-tfidf-unb-prep    0.865442    0.791545      0.828493   0.805391   \n",
       "rf-tfidf-unb          0.997409    0.996561      0.996985   0.816786   \n",
       "\n",
       "                    F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep   0.733850     0.784962  \n",
       "mnb-tfidf-unb        0.715695     0.775766  \n",
       "rf-tfidf-unb-prep    0.698470     0.762672  \n",
       "knn-tfidf-unb        0.705000     0.756617  \n",
       "knn-tfidf-unb-prep   0.696893     0.751142  \n",
       "rf-tfidf-unb         0.672161     0.744474  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c8343",
   "metadata": {},
   "source": [
    "## Class balancing, minimal preprocessing (KNN, MNB, RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "402b4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight, undersampling, oversampling, smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fb16da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight param\n",
    "# knn: none\n",
    "# mnb: fit_prior = False\n",
    "# rf: class_weight = 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7143195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use class_weight param (if avail) WITH other\n",
    "# sampling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c12e40",
   "metadata": {},
   "source": [
    "### Undersampling & class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fad0c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as resample_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2bce882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.preprocessed_txt,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eab1e446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.848382\n",
      "F1_1_Train      0.789732\n",
      "F1_Avg_Train    0.819057\n",
      "F1_0_Test       0.784667\n",
      "F1_1_Test       0.699686\n",
      "F1_Avg_Test     0.742176\n",
      "Name: knn-tfidf-under-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# undersampled knn on preprocessed data\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                              RandomUnderSampler(),\n",
    "                              KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"knn-tfidf-under-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea6c8ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.920773\n",
      "F1_1_Train      0.897189\n",
      "F1_Avg_Train    0.908981\n",
      "F1_0_Test       0.794393\n",
      "F1_1_Test       0.736132\n",
      "F1_Avg_Test     0.765262\n",
      "Name: mnb-tfidf-under-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# undersampled, balanced mnb on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        RandomUnderSampler(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-under-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4e76bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.981882\n",
      "F1_1_Train      0.976762\n",
      "F1_Avg_Train    0.979322\n",
      "F1_0_Test       0.814895\n",
      "F1_1_Test       0.712490\n",
      "F1_Avg_Test     0.763692\n",
      "Name: rf-tfidf-under-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# random forest on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        RandomUnderSampler(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"rf-tfidf-under-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b8eac63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-under-prep</th>\n",
       "      <td>0.920773</td>\n",
       "      <td>0.897189</td>\n",
       "      <td>0.908981</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736132</td>\n",
       "      <td>0.765262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-under-prep</th>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.976762</td>\n",
       "      <td>0.979322</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.712490</td>\n",
       "      <td>0.763692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996749</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.762672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb-prep</th>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.816786</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.744474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-under-prep</th>\n",
       "      <td>0.848382</td>\n",
       "      <td>0.789732</td>\n",
       "      <td>0.819057</td>\n",
       "      <td>0.784667</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>0.742176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep      0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb           0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-under-prep    0.920773    0.897189      0.908981   0.794393   \n",
       "rf-tfidf-under-prep     0.981882    0.976762      0.979322   0.814895   \n",
       "rf-tfidf-unb-prep       0.997554    0.996749      0.997152   0.826873   \n",
       "knn-tfidf-unb           0.865827    0.799016      0.832421   0.808234   \n",
       "knn-tfidf-unb-prep      0.865442    0.791545      0.828493   0.805391   \n",
       "rf-tfidf-unb            0.997409    0.996561      0.996985   0.816786   \n",
       "knn-tfidf-under-prep    0.848382    0.789732      0.819057   0.784667   \n",
       "\n",
       "                      F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep     0.733850     0.784962  \n",
       "mnb-tfidf-unb          0.715695     0.775766  \n",
       "mnb-tfidf-under-prep   0.736132     0.765262  \n",
       "rf-tfidf-under-prep    0.712490     0.763692  \n",
       "rf-tfidf-unb-prep      0.698470     0.762672  \n",
       "knn-tfidf-unb          0.705000     0.756617  \n",
       "knn-tfidf-unb-prep     0.696893     0.751142  \n",
       "rf-tfidf-unb           0.672161     0.744474  \n",
       "knn-tfidf-under-prep   0.699686     0.742176  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b1ba29",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Oversampling and class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f11ea994",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b3220d2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.preprocessed_txt,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6fb8598",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.857022\n",
      "F1_1_Train      0.801646\n",
      "F1_Avg_Train    0.829334\n",
      "F1_0_Test       0.782854\n",
      "F1_1_Test       0.697565\n",
      "F1_Avg_Test     0.740209\n",
      "Name: knn-tfidf-over-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# oversampled knn on preprocessed data\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        RandomOverSampler(),\n",
    "                        KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"knn-tfidf-over-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1385bb80",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.934497\n",
      "F1_1_Train      0.911719\n",
      "F1_Avg_Train    0.923108\n",
      "F1_0_Test       0.797688\n",
      "F1_1_Test       0.734043\n",
      "F1_Avg_Test     0.765865\n",
      "Name: mnb-tfidf-over-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# oversampled, balanced mnb on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        RandomOverSampler(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-over-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "605a1a9c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.997409\n",
      "F1_1_Train      0.996561\n",
      "F1_Avg_Train    0.996985\n",
      "F1_0_Test       0.820513\n",
      "F1_1_Test       0.697797\n",
      "F1_Avg_Test     0.759155\n",
      "Name: rf-tfidf-over-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# oversampled random forest on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        RandomOverSampler(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"rf-tfidf-over-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8d266da",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-under-prep</th>\n",
       "      <td>0.920773</td>\n",
       "      <td>0.897189</td>\n",
       "      <td>0.908981</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736132</td>\n",
       "      <td>0.765262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-under-prep</th>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.976762</td>\n",
       "      <td>0.979322</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.712490</td>\n",
       "      <td>0.763692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996749</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.762672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-over-prep</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>0.759155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb-prep</th>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.816786</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.744474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-under-prep</th>\n",
       "      <td>0.848382</td>\n",
       "      <td>0.789732</td>\n",
       "      <td>0.819057</td>\n",
       "      <td>0.784667</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>0.742176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-over-prep</th>\n",
       "      <td>0.857022</td>\n",
       "      <td>0.801646</td>\n",
       "      <td>0.829334</td>\n",
       "      <td>0.782854</td>\n",
       "      <td>0.697565</td>\n",
       "      <td>0.740209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep      0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb           0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-over-prep     0.934497    0.911719      0.923108   0.797688   \n",
       "mnb-tfidf-under-prep    0.920773    0.897189      0.908981   0.794393   \n",
       "rf-tfidf-under-prep     0.981882    0.976762      0.979322   0.814895   \n",
       "rf-tfidf-unb-prep       0.997554    0.996749      0.997152   0.826873   \n",
       "rf-tfidf-over-prep      0.997409    0.996561      0.996985   0.820513   \n",
       "knn-tfidf-unb           0.865827    0.799016      0.832421   0.808234   \n",
       "knn-tfidf-unb-prep      0.865442    0.791545      0.828493   0.805391   \n",
       "rf-tfidf-unb            0.997409    0.996561      0.996985   0.816786   \n",
       "knn-tfidf-under-prep    0.848382    0.789732      0.819057   0.784667   \n",
       "knn-tfidf-over-prep     0.857022    0.801646      0.829334   0.782854   \n",
       "\n",
       "                      F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep     0.733850     0.784962  \n",
       "mnb-tfidf-unb          0.715695     0.775766  \n",
       "mnb-tfidf-over-prep    0.734043     0.765865  \n",
       "mnb-tfidf-under-prep   0.736132     0.765262  \n",
       "rf-tfidf-under-prep    0.712490     0.763692  \n",
       "rf-tfidf-unb-prep      0.698470     0.762672  \n",
       "rf-tfidf-over-prep     0.697797     0.759155  \n",
       "knn-tfidf-unb          0.705000     0.756617  \n",
       "knn-tfidf-unb-prep     0.696893     0.751142  \n",
       "rf-tfidf-unb           0.672161     0.744474  \n",
       "knn-tfidf-under-prep   0.699686     0.742176  \n",
       "knn-tfidf-over-prep    0.697565     0.740209  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b03b2f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SMOTE and class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a18ceb23",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f83f913c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.preprocessed_txt,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "021a7dbd",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.453258\n",
      "F1_1_Train      0.669477\n",
      "F1_Avg_Train    0.561367\n",
      "F1_0_Test       0.422778\n",
      "F1_1_Test       0.645469\n",
      "F1_Avg_Test     0.534124\n",
      "Name: knn-tfidf-smote-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smote knn on preprocessed data\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        SMOTE(),\n",
    "                        KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"knn-tfidf-smote-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "979d40e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.934886\n",
      "F1_1_Train      0.913268\n",
      "F1_Avg_Train    0.924077\n",
      "F1_0_Test       0.798841\n",
      "F1_1_Test       0.737320\n",
      "F1_Avg_Test     0.768080\n",
      "Name: mnb-tfidf-smote-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smote, balanced mnb on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        SMOTE(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-smote-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "847f79de",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.931020\n",
      "F1_1_Train      0.907624\n",
      "F1_Avg_Train    0.919322\n",
      "F1_0_Test       0.801615\n",
      "F1_1_Test       0.737805\n",
      "F1_Avg_Test     0.769710\n",
      "Name: mnb-tfidf-smote-def-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smote, default mnb on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        SMOTE(),\n",
    "                        MultinomialNB())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-smote-def-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8998ab5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.997554\n",
      "F1_1_Train      0.996750\n",
      "F1_Avg_Train    0.997152\n",
      "F1_0_Test       0.827550\n",
      "F1_1_Test       0.701345\n",
      "F1_Avg_Test     0.764448\n",
      "Name: rf-tfidf-smote-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smote random forest on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        SMOTE(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"rf-tfidf-smote-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0bfa68e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b5ba3",
   "metadata": {},
   "source": [
    "# spaCy Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19aee63",
   "metadata": {},
   "source": [
    "## MNB, no class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6baf7c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed Reason earthquake ALLAH forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near La Ronge Sask Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive wildfire evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo Ruby Alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                   preprocessed_txt  \n",
       "0       1               deed Reason earthquake ALLAH forgive  \n",
       "1       1              forest fire near La Ronge Sask Canada  \n",
       "2       1  resident ask shelter place notify officer evac...  \n",
       "3       1  13,000 people receive wildfire evacuation orde...  \n",
       "4       1  got send photo Ruby Alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6eba1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84e66a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make spacy vectors (takes awhile!)\n",
    "train_df['spacy_vector'] = train_df['text'].apply(lambda x: nlp(x).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd8dc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.spacy_vector.values,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "733f31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eea3c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf00d168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.707195\n",
      "F1_1_Train      0.628678\n",
      "F1_Avg_Train    0.667937\n",
      "F1_0_Test       0.704639\n",
      "F1_1_Test       0.625465\n",
      "F1_Avg_Test     0.665052\n",
      "Name: mnb-spacyvec-unb, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-under-prep</th>\n",
       "      <td>0.920773</td>\n",
       "      <td>0.897189</td>\n",
       "      <td>0.908981</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736132</td>\n",
       "      <td>0.765262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-smote-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.827550</td>\n",
       "      <td>0.701345</td>\n",
       "      <td>0.764448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-under-prep</th>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.976762</td>\n",
       "      <td>0.979322</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.712490</td>\n",
       "      <td>0.763692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996749</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.762672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-over-prep</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>0.759155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb-prep</th>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.816786</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.744474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-under-prep</th>\n",
       "      <td>0.848382</td>\n",
       "      <td>0.789732</td>\n",
       "      <td>0.819057</td>\n",
       "      <td>0.784667</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>0.742176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-over-prep</th>\n",
       "      <td>0.857022</td>\n",
       "      <td>0.801646</td>\n",
       "      <td>0.829334</td>\n",
       "      <td>0.782854</td>\n",
       "      <td>0.697565</td>\n",
       "      <td>0.740209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-spacyvec-unb</th>\n",
       "      <td>0.707195</td>\n",
       "      <td>0.628678</td>\n",
       "      <td>0.667937</td>\n",
       "      <td>0.704639</td>\n",
       "      <td>0.625465</td>\n",
       "      <td>0.665052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-smote-prep</th>\n",
       "      <td>0.453258</td>\n",
       "      <td>0.669477</td>\n",
       "      <td>0.561367</td>\n",
       "      <td>0.422778</td>\n",
       "      <td>0.645469</td>\n",
       "      <td>0.534124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "mnb-tfidf-under-prep        0.920773    0.897189      0.908981   0.794393   \n",
       "rf-tfidf-smote-prep         0.997554    0.996750      0.997152   0.827550   \n",
       "rf-tfidf-under-prep         0.981882    0.976762      0.979322   0.814895   \n",
       "rf-tfidf-unb-prep           0.997554    0.996749      0.997152   0.826873   \n",
       "rf-tfidf-over-prep          0.997409    0.996561      0.996985   0.820513   \n",
       "knn-tfidf-unb               0.865827    0.799016      0.832421   0.808234   \n",
       "knn-tfidf-unb-prep          0.865442    0.791545      0.828493   0.805391   \n",
       "rf-tfidf-unb                0.997409    0.996561      0.996985   0.816786   \n",
       "knn-tfidf-under-prep        0.848382    0.789732      0.819057   0.784667   \n",
       "knn-tfidf-over-prep         0.857022    0.801646      0.829334   0.782854   \n",
       "mnb-spacyvec-unb            0.707195    0.628678      0.667937   0.704639   \n",
       "knn-tfidf-smote-prep        0.453258    0.669477      0.561367   0.422778   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  \n",
       "mnb-tfidf-under-prep       0.736132     0.765262  \n",
       "rf-tfidf-smote-prep        0.701345     0.764448  \n",
       "rf-tfidf-under-prep        0.712490     0.763692  \n",
       "rf-tfidf-unb-prep          0.698470     0.762672  \n",
       "rf-tfidf-over-prep         0.697797     0.759155  \n",
       "knn-tfidf-unb              0.705000     0.756617  \n",
       "knn-tfidf-unb-prep         0.696893     0.751142  \n",
       "rf-tfidf-unb               0.672161     0.744474  \n",
       "knn-tfidf-under-prep       0.699686     0.742176  \n",
       "knn-tfidf-over-prep        0.697565     0.740209  \n",
       "mnb-spacyvec-unb           0.625465     0.665052  \n",
       "knn-tfidf-smote-prep       0.645469     0.534124  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnb, spacy word vectors\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(scaled_train_embed, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            scaled_train_embed, \n",
    "            scaled_test_embed, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"mnb-spacyvec-unb\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a790b573",
   "metadata": {},
   "source": [
    "## KNN, no class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a8638eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.842459\n",
      "F1_1_Train      0.776741\n",
      "F1_Avg_Train    0.809600\n",
      "F1_0_Test       0.754886\n",
      "F1_1_Test       0.650199\n",
      "F1_Avg_Test     0.702542\n",
      "Name: knn-spacyvec-unb, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-under-prep</th>\n",
       "      <td>0.920773</td>\n",
       "      <td>0.897189</td>\n",
       "      <td>0.908981</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736132</td>\n",
       "      <td>0.765262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-smote-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.827550</td>\n",
       "      <td>0.701345</td>\n",
       "      <td>0.764448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-under-prep</th>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.976762</td>\n",
       "      <td>0.979322</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.712490</td>\n",
       "      <td>0.763692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996749</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.762672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-over-prep</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>0.759155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb-prep</th>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.816786</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.744474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-under-prep</th>\n",
       "      <td>0.848382</td>\n",
       "      <td>0.789732</td>\n",
       "      <td>0.819057</td>\n",
       "      <td>0.784667</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>0.742176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-over-prep</th>\n",
       "      <td>0.857022</td>\n",
       "      <td>0.801646</td>\n",
       "      <td>0.829334</td>\n",
       "      <td>0.782854</td>\n",
       "      <td>0.697565</td>\n",
       "      <td>0.740209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-spacyvec-unb</th>\n",
       "      <td>0.842459</td>\n",
       "      <td>0.776741</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>0.754886</td>\n",
       "      <td>0.650199</td>\n",
       "      <td>0.702542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-spacyvec-unb</th>\n",
       "      <td>0.707195</td>\n",
       "      <td>0.628678</td>\n",
       "      <td>0.667937</td>\n",
       "      <td>0.704639</td>\n",
       "      <td>0.625465</td>\n",
       "      <td>0.665052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-smote-prep</th>\n",
       "      <td>0.453258</td>\n",
       "      <td>0.669477</td>\n",
       "      <td>0.561367</td>\n",
       "      <td>0.422778</td>\n",
       "      <td>0.645469</td>\n",
       "      <td>0.534124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "mnb-tfidf-under-prep        0.920773    0.897189      0.908981   0.794393   \n",
       "rf-tfidf-smote-prep         0.997554    0.996750      0.997152   0.827550   \n",
       "rf-tfidf-under-prep         0.981882    0.976762      0.979322   0.814895   \n",
       "rf-tfidf-unb-prep           0.997554    0.996749      0.997152   0.826873   \n",
       "rf-tfidf-over-prep          0.997409    0.996561      0.996985   0.820513   \n",
       "knn-tfidf-unb               0.865827    0.799016      0.832421   0.808234   \n",
       "knn-tfidf-unb-prep          0.865442    0.791545      0.828493   0.805391   \n",
       "rf-tfidf-unb                0.997409    0.996561      0.996985   0.816786   \n",
       "knn-tfidf-under-prep        0.848382    0.789732      0.819057   0.784667   \n",
       "knn-tfidf-over-prep         0.857022    0.801646      0.829334   0.782854   \n",
       "knn-spacyvec-unb            0.842459    0.776741      0.809600   0.754886   \n",
       "mnb-spacyvec-unb            0.707195    0.628678      0.667937   0.704639   \n",
       "knn-tfidf-smote-prep        0.453258    0.669477      0.561367   0.422778   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  \n",
       "mnb-tfidf-under-prep       0.736132     0.765262  \n",
       "rf-tfidf-smote-prep        0.701345     0.764448  \n",
       "rf-tfidf-under-prep        0.712490     0.763692  \n",
       "rf-tfidf-unb-prep          0.698470     0.762672  \n",
       "rf-tfidf-over-prep         0.697797     0.759155  \n",
       "knn-tfidf-unb              0.705000     0.756617  \n",
       "knn-tfidf-unb-prep         0.696893     0.751142  \n",
       "rf-tfidf-unb               0.672161     0.744474  \n",
       "knn-tfidf-under-prep       0.699686     0.742176  \n",
       "knn-tfidf-over-prep        0.697565     0.740209  \n",
       "knn-spacyvec-unb           0.650199     0.702542  \n",
       "mnb-spacyvec-unb           0.625465     0.665052  \n",
       "knn-tfidf-smote-prep       0.645469     0.534124  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knn-spacyvec-unb\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb44d2",
   "metadata": {},
   "source": [
    "## RF, no class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45bcfe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.990831\n",
      "F1_1_Train      0.987692\n",
      "F1_Avg_Train    0.989262\n",
      "F1_0_Test       0.801498\n",
      "F1_1_Test       0.684792\n",
      "F1_Avg_Test     0.743145\n",
      "Name: rf-spacyvec-unb, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rf-spacyvec-unb\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f54c672",
   "metadata": {},
   "source": [
    "## MNB, class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a738f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.676200\n",
      "F1_1_Train      0.653755\n",
      "F1_Avg_Train    0.664977\n",
      "F1_0_Test       0.666240\n",
      "F1_1_Test       0.647773\n",
      "F1_Avg_Test     0.657007\n",
      "Name: mnb-spacyvec-under, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersampled, balanced mnb on preprocessed text\n",
    "\n",
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.spacy_vector.values,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)\n",
    "\n",
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)\n",
    "\n",
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)\n",
    "\n",
    "clf = resample_pipeline(RandomUnderSampler(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "clf.fit(scaled_train_embed, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            scaled_train_embed, \n",
    "            scaled_test_embed, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"mnb-spacyvec-under\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "116eea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.676620\n",
      "F1_1_Train      0.653977\n",
      "F1_Avg_Train    0.665298\n",
      "F1_0_Test       0.667093\n",
      "F1_1_Test       0.648211\n",
      "F1_Avg_Test     0.657652\n",
      "Name: mnb-spacyvec-over, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oversampled, balanced mnb on preprocessed text\n",
    "\n",
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.spacy_vector.values,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)\n",
    "\n",
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)\n",
    "\n",
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)\n",
    "\n",
    "clf = resample_pipeline(RandomOverSampler(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "clf.fit(scaled_train_embed, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            scaled_train_embed, \n",
    "            scaled_test_embed, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"mnb-spacyvec-over\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7c227661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.676298\n",
      "F1_1_Train      0.653290\n",
      "F1_Avg_Train    0.664794\n",
      "F1_0_Test       0.663677\n",
      "F1_1_Test       0.646465\n",
      "F1_Avg_Test     0.655071\n",
      "Name: mnb-spacyvec-smote, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smoted, balanced mnb on preprocessed text\n",
    "\n",
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.spacy_vector.values,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)\n",
    "\n",
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)\n",
    "\n",
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "clf.fit(scaled_train_embed, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            scaled_train_embed, \n",
    "            scaled_test_embed, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"mnb-spacyvec-smote\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e648f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.676284\n",
      "F1_1_Train      0.652248\n",
      "F1_Avg_Train    0.664266\n",
      "F1_0_Test       0.667093\n",
      "F1_1_Test       0.648211\n",
      "F1_Avg_Test     0.657652\n",
      "Name: mnb-spacyvec-smote, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smoted, unbalanced mnb on preprocessed text\n",
    "\n",
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.spacy_vector.values,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)\n",
    "\n",
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)\n",
    "\n",
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        MultinomialNB())\n",
    "clf.fit(scaled_train_embed, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            scaled_train_embed, \n",
    "            scaled_test_embed, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"mnb-spacyvec-smote\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d820471",
   "metadata": {},
   "source": [
    "## KNN, class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "512d36a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.817106\n",
      "F1_1_Train      0.772040\n",
      "F1_Avg_Train    0.794573\n",
      "F1_0_Test       0.720903\n",
      "F1_1_Test       0.654919\n",
      "F1_Avg_Test     0.687911\n",
      "Name: knn-spacyvec-under, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# undersampled knn\n",
    "\n",
    "clf = resample_pipeline(RandomUnderSampler(),\n",
    "                        KNeighborsClassifier(n_neighbors = 5,\n",
    "                                            metric = 'euclidean'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knn-spacyvec-under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0c99a363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.828014\n",
      "F1_1_Train      0.784922\n",
      "F1_Avg_Train    0.806468\n",
      "F1_0_Test       0.711824\n",
      "F1_1_Test       0.644167\n",
      "F1_Avg_Test     0.677996\n",
      "Name: knn-spacyvec-over, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# oversampled knn\n",
    "\n",
    "clf = resample_pipeline(RandomOverSampler(),\n",
    "                        KNeighborsClassifier(n_neighbors = 5,\n",
    "                                            metric = 'euclidean'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knn-spacyvec-over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "34da746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.786374\n",
      "F1_1_Train      0.772465\n",
      "F1_Avg_Train    0.779420\n",
      "F1_0_Test       0.654402\n",
      "F1_1_Test       0.654856\n",
      "F1_Avg_Test     0.654629\n",
      "Name: knn-spacyvec-smote, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smoted knn\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        KNeighborsClassifier(n_neighbors = 5,\n",
    "                                            metric = 'euclidean'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knn-spacyvec-smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d710a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.812723\n",
      "F1_1_Train      0.768892\n",
      "F1_Avg_Train    0.790808\n",
      "F1_0_Test       0.726521\n",
      "F1_1_Test       0.657797\n",
      "F1_Avg_Test     0.692159\n",
      "Name: knndef-spacyvec-under, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# undersampled default knn\n",
    "\n",
    "clf = resample_pipeline(RandomUnderSampler(),\n",
    "                        KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knndef-spacyvec-under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "341470a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.826461\n",
      "F1_1_Train      0.784847\n",
      "F1_Avg_Train    0.805654\n",
      "F1_0_Test       0.720238\n",
      "F1_1_Test       0.655930\n",
      "F1_Avg_Test     0.688084\n",
      "Name: knndef-spacyvec-over, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# oversampled default knn\n",
    "\n",
    "clf = resample_pipeline(RandomOverSampler(),\n",
    "                        KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knndef-spacyvec-over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "149a2519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.785256\n",
      "F1_1_Train      0.774411\n",
      "F1_Avg_Train    0.779834\n",
      "F1_0_Test       0.650667\n",
      "F1_1_Test       0.661061\n",
      "F1_Avg_Test     0.655864\n",
      "Name: knndef-spacyvec-smote, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smoted default knn\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knndef-spacyvec-smote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d301303",
   "metadata": {},
   "source": [
    "## RF, class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ee3ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.966774\n",
      "F1_1_Train      0.957977\n",
      "F1_Avg_Train    0.962376\n",
      "F1_0_Test       0.779236\n",
      "F1_1_Test       0.700696\n",
      "F1_Avg_Test     0.739966\n",
      "Name: rf-spacyvec-under, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf under\n",
    "\n",
    "clf = resample_pipeline(RandomUnderSampler(),\n",
    "                        RandomForestClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rf-spacyvec-under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3f170c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.963695\n",
      "F1_1_Train      0.954478\n",
      "F1_Avg_Train    0.959087\n",
      "F1_0_Test       0.774453\n",
      "F1_1_Test       0.700306\n",
      "F1_Avg_Test     0.737380\n",
      "Name: rfbal-spacyvec-under, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf under bal\n",
    "\n",
    "clf = resample_pipeline(RandomUnderSampler(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rfbal-spacyvec-under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "095dedfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.990085\n",
      "F1_1_Train      0.986784\n",
      "F1_Avg_Train    0.988434\n",
      "F1_0_Test       0.797157\n",
      "F1_1_Test       0.695152\n",
      "F1_Avg_Test     0.746154\n",
      "Name: rf-spacyvec-over, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf over\n",
    "\n",
    "clf = resample_pipeline(RandomOverSampler(),\n",
    "                        RandomForestClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rf-spacyvec-over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2bb47ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.990515\n",
      "F1_1_Train      0.987361\n",
      "F1_Avg_Train    0.988938\n",
      "F1_0_Test       0.795640\n",
      "F1_1_Test       0.690339\n",
      "F1_Avg_Test     0.742989\n",
      "Name: rfbal-spacyvec-over, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf over bal\n",
    "\n",
    "clf = resample_pipeline(RandomOverSampler(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rfbal-spacyvec-over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6346b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.990815\n",
      "F1_1_Train      0.987721\n",
      "F1_Avg_Train    0.989268\n",
      "F1_0_Test       0.797357\n",
      "F1_1_Test       0.700813\n",
      "F1_Avg_Test     0.749085\n",
      "Name: rf-spacyvec-smote, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf smote\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        RandomForestClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rf-spacyvec-smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a81c2a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.990826\n",
      "F1_1_Train      0.987702\n",
      "F1_Avg_Train    0.989264\n",
      "F1_0_Test       0.795806\n",
      "F1_1_Test       0.700162\n",
      "F1_Avg_Test     0.747984\n",
      "Name: rfbal-spacyvec-smote, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf smote with balancing\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rfbal-spacyvec-smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "044a5677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c900490",
   "metadata": {},
   "source": [
    "# Gensim word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ae435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1c20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1683710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04042ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3bcabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess and get gensim doc vector\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def preprocess_and_vectorize(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_punct or token.is_stop:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return wv.get_mean_vector(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7bb4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text into gensim word embeddings\n",
    "\n",
    "df['gensim_vector'] = df['text'].apply(lambda text: preprocess_and_vectorize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b633f5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>gensim_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.05016107, 0.00387215, 0.047061782, 0.028958...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.03064329, 0.0030595234, 0.0369662, 0.020602...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0048536863, 0.011481234, 0.016771162, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.060398173, -0.012511074, -0.0018801317, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.021673834, 0.0012636562, -0.031610973, 0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                      gensim_vector  \n",
       "0       1  [0.05016107, 0.00387215, 0.047061782, 0.028958...  \n",
       "1       1  [0.03064329, 0.0030595234, 0.0369662, 0.020602...  \n",
       "2       1  [-0.0048536863, 0.011481234, 0.016771162, -0.0...  \n",
       "3       1  [0.060398173, -0.012511074, -0.0018801317, 0.0...  \n",
       "4       1  [0.021673834, 0.0012636562, -0.031610973, 0.03...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e5fe6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.gensim_vector.values,\n",
    "    df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de3c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2d np arrays for X train and test sets\n",
    "import numpy as np\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a4be949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.891286\n",
      "F1_1_Train      0.841212\n",
      "F1_Avg_Train    0.866249\n",
      "F1_0_Test       0.816304\n",
      "F1_1_Test       0.737849\n",
      "F1_Avg_Test     0.777076\n",
      "Name: gbc-gensim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"gbc-gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffd97049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gbc-gensim</th>\n",
       "      <td>0.891286</td>\n",
       "      <td>0.841212</td>\n",
       "      <td>0.866249</td>\n",
       "      <td>0.816304</td>\n",
       "      <td>0.737849</td>\n",
       "      <td>0.777076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  F1_1_Test  \\\n",
       "gbc-gensim    0.891286    0.841212      0.866249   0.816304   0.737849   \n",
       "\n",
       "            F1_Avg_Test  \n",
       "gbc-gensim     0.777076  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = \"F1_Avg_Test\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda21f6",
   "metadata": {},
   "source": [
    "more gensim:\n",
    "other models available:\n",
    "- twitter, wiki\n",
    "- glove, fasttext\n",
    "\n",
    "consider gensim models:\n",
    "- glove-twitter-200\n",
    "- word2vec-google-news-300\n",
    "- glove-wiki-gigaword-300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c849dc",
   "metadata": {},
   "source": [
    "# Fast Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "004f6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d759f01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1058a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38860b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['__label__1', '__label__0'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format target labels for fasttext\n",
    "df['target'] = \"__label__\" + df['target'].astype(str)\n",
    "\n",
    "# check\n",
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da9780e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 Our Deeds are the Reason of this #e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 All residents asked to 'shelter in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 13,000 people receive #wildfires ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 Just got sent this photo from Ruby ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "       target                                        target_text  \n",
       "0  __label__1  __label__1 Our Deeds are the Reason of this #e...  \n",
       "1  __label__1  __label__1 Forest fire near La Ronge Sask. Canada  \n",
       "2  __label__1  __label__1 All residents asked to 'shelter in ...  \n",
       "3  __label__1  __label__1 13,000 people receive #wildfires ev...  \n",
       "4  __label__1  __label__1 Just got sent this photo from Ruby ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two columns so the text is on the same line as the label\n",
    "# for fasttext formatting requirements\n",
    "df['target_text'] = df['target'] + \" \" + df['text']\n",
    "\n",
    "# check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67e51166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 our deeds are the reason of this ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 all residents asked to 'shelter in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 13 000 people receive wildfires eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 just got sent this photo from ruby ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "       target                                        target_text  \n",
       "0  __label__1  __label__1 our deeds are the reason of this ea...  \n",
       "1  __label__1   __label__1 forest fire near la ronge sask canada  \n",
       "2  __label__1  __label__1 all residents asked to 'shelter in ...  \n",
       "3  __label__1  __label__1 13 000 people receive wildfires eva...  \n",
       "4  __label__1  __label__1 just got sent this photo from ruby ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define preprocess function\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"[^\\w\\s\\']\", \" \", text)\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r\"\\\\n+\", \" \", text)\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    return text\n",
    "\n",
    "# apply preprocess function to df\n",
    "df['target_text'] = df['target_text'].map(preprocess)\n",
    "\n",
    "# check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ce80890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 our deeds are the reason of this ea...</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 forest fire near la ronge sask canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 all residents asked to 'shelter in ...</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 13 000 people receive wildfires eva...</td>\n",
       "      <td>13 000 people receive wildfires evacuation ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 just got sent this photo from ruby ...</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "       target                                        target_text  \\\n",
       "0  __label__1  __label__1 our deeds are the reason of this ea...   \n",
       "1  __label__1   __label__1 forest fire near la ronge sask canada   \n",
       "2  __label__1  __label__1 all residents asked to 'shelter in ...   \n",
       "3  __label__1  __label__1 13 000 people receive wildfires eva...   \n",
       "4  __label__1  __label__1 just got sent this photo from ruby ...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  our deeds are the reason of this earthquake ma...  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  all residents asked to 'shelter in place' are ...  \n",
       "3  13 000 people receive wildfires evacuation ord...  \n",
       "4  just got sent this photo from ruby alaska as s...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make preprocessed text column (without label) to test model on\n",
    "\n",
    "df['processed_text'] = df['text'].map(preprocess)\n",
    "\n",
    "# check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bfaae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6090, 7)\n",
      "(1523, 7)\n"
     ]
    }
   ],
   "source": [
    "# tts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, \n",
    "                               test_size = 0.2, \n",
    "                               stratify = df.target)\n",
    "\n",
    "# check\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21925e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save formatted and labeled column in file for fasttext to train on\n",
    "\n",
    "import csv\n",
    "\n",
    "train.to_csv(\"disaster_train_fasttext.csv\", \n",
    "             columns = [\"target_text\"], \n",
    "             index = False, \n",
    "             header = False,\n",
    "             quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa12cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with labels\n",
    "import fasttext\n",
    "\n",
    "model = fasttext.train_supervised(input = 'disaster_train_fasttext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "537fffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "print(len(test.processed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f02182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make file with processed text (without labels) in test set\n",
    "# to test model on\n",
    "\n",
    "test.to_csv(\"disaster_test_fasttext.csv\", \n",
    "             columns = [\"processed_text\"], \n",
    "             index = False, \n",
    "             header = False,\n",
    "             quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "feaea01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "print(len(test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a626d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make file with true labels for test set to compare model predictions to\n",
    "\n",
    "test.to_csv(\"disaster_test_fasttext_true_labels.csv\",\n",
    "           columns = ['target'],\n",
    "           index = False,\n",
    "           header = False,\n",
    "           quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4485fe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n",
      "                                                   0\n",
      "0  lightning causes six new fires on vancouveri...\n",
      "1  unr continues severe thunderstorm warning wind...\n",
      "2  fevwarrior in the vault that could take a look...\n",
      "3  captain abbott must go down with lnp boat refu...\n",
      "4  storm batters top half of north island a viole...\n",
      "5  oops bounty hunters try to raid phoenix police...\n",
      "6  illinois tornado slipped under the radar emerg...\n",
      "7              forest fire near la ronge sask canada\n",
      "8  i've been bleeding in your silence \\ni feel sa...\n",
      "9  melrises gayler1969 wwwbigbaldhead jessienojok...\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "# with open('disaster_test_fasttext.csv', 'r', encoding = 'utf-8') as f:\n",
    "#     test_data = f.readlines()\n",
    "\n",
    "test_data = pd.read_csv(\"disaster_test_fasttext.csv\", \n",
    "                        header = None,\n",
    "                        quoting = csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "print(len(test_data))\n",
    "    \n",
    "# check\n",
    "print(test_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "839d348e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lightning causes six new fires on vancouverisland http t co vdiliicyr5'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09a90c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newline characters\n",
    "# test_data = [line.strip() for line in test_data]\n",
    "\n",
    "# check\n",
    "# print(test_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10fe9164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "# check length of test data\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a51151cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lightning causes six new fires on vancouverisland http t co vdiliicyr5',\n",
       " 'unr continues severe thunderstorm warning wind 60 mph hail lt 75 in for weston wy and custer fall river pennington sd till 7 15 p _',\n",
       " \"fevwarrior in the vault that could take a look at those wounds of yours if you'd like to go to one of these places first ' zarry has had\",\n",
       " 'captain abbott must go down with lnp boat refugees christianvalues https t co kp5dpoaf58',\n",
       " 'storm batters top half of north island a violent overnight storm has battered the upper north island uprootin http t co fhvokmphed',\n",
       " \"oops bounty hunters try to raid phoenix police chief's home a group of armed bounty hunters surrounded the h http t co dgelj8ryt9\",\n",
       " 'illinois tornado slipped under the radar emergency officials say http t co p4kofytkdx',\n",
       " 'forest fire near la ronge sask canada',\n",
       " \"i've been bleeding in your silence \\ni feel safer in your violence\",\n",
       " 'melrises gayler1969 wwwbigbaldhead jessienojoke melissaross9847 if my monty python is up to date as bloody far as he wants to go']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert test data to list\n",
    "test_data_list = test_data[0].tolist()\n",
    "\n",
    "# check\n",
    "test_data_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60f48396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n",
      "            0\n",
      "0  __label__1\n",
      "1  __label__1\n",
      "2  __label__0\n",
      "3  __label__0\n",
      "4  __label__1\n",
      "5  __label__1\n",
      "6  __label__1\n",
      "7  __label__1\n",
      "8  __label__0\n",
      "9  __label__0\n"
     ]
    }
   ],
   "source": [
    "true_labels = pd.read_csv(\"disaster_test_fasttext_true_labels.csv\", \n",
    "                        header = None,\n",
    "                        quoting = csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "print(len(true_labels))\n",
    "    \n",
    "# check\n",
    "print(true_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d242d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "# check length of true_labels\n",
    "print(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7e44fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__1',\n",
       " '__label__1',\n",
       " '__label__0',\n",
       " '__label__0',\n",
       " '__label__1',\n",
       " '__label__1',\n",
       " '__label__1',\n",
       " '__label__1',\n",
       " '__label__0',\n",
       " '__label__0']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert true labels to list\n",
    "true_labels_list = true_labels[0].tolist()\n",
    "\n",
    "# check\n",
    "true_labels_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d5a88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line of code kills the kernel\n",
    "\n",
    "# predict labels for test data\n",
    "# model.predict(test_data[0][0])\n",
    "# predictions = [model.predict(line)[0] for line in test_data.iterrows()]\n",
    "\n",
    "# check\n",
    "# print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bfa35da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check length of predictions\n",
    "# print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80dbae4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lightning causes six new fires on vancouverisland http t co vdiliicyr5'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is causing my kernel to crash\n",
    "# https://fasttext.cc/docs/en/supervised-tutorial.html\n",
    "\n",
    "model.predict(\"which baking dish is best to bake a banana bread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01122b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11f2ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_prediction = model.predict(test_data_list[0])\n",
    "# test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a642bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the f1 score\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# f1 = f1_score(true_labels, predictions, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f89ee335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model.test(\"disaster_test_fasttext\")\n",
    "\n",
    "# # three output numbers: size of test samples, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1262002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get f1?\n",
    "# model.test_label(\"disaster_test_fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40c98eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(\"disaster_test_fasttext\")\n",
    "\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a5ea631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad88bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e60a567a",
   "metadata": {},
   "source": [
    "# Other\n",
    "\n",
    "categorical nb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45e00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
