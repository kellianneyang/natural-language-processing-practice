{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81565380",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Natural Language Processing with Disaster Tweets (Kaggle Competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64dd07cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f88263",
   "metadata": {},
   "source": [
    "# Starter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d003ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb817cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "train_df = pd.read_csv(\"Data/train.csv\")\n",
    "test_df = pd.read_csv(\"Data/test.csv\")\n",
    "\n",
    "# check\n",
    "train_df.info()\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cabfb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a691924a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class balance\n",
    "train_df['target'].value_counts()\n",
    "\n",
    "# the classes are a bit unbalanced (57% to 43%),\n",
    "# so we may want to try some class balancing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0284d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check uniqueness of id column\n",
    "train_df['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548a660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love fruits\n",
      "Summer is lovely\n",
      "My car is so fast\n",
      "What a goooooooaaaaaal!!!!!!\n",
      "this is ridiculous....\n",
      "London is cool ;)\n",
      "Love skiing\n",
      "What a wonderful day!\n",
      "LOOOOOOL\n"
     ]
    }
   ],
   "source": [
    "# check examples of non-disaster tweets (target = 0)\n",
    "nondisaster_df = train_df[train_df['target'] == 0]\n",
    "\n",
    "for tweet in nondisaster_df['text'].values[1:10]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1f8959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest fire near La Ronge Sask. Canada\n",
      "All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
      "13,000 people receive #wildfires evacuation orders in California \n",
      "Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n",
      "#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires\n",
      "#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas\n",
      "I'm on top of the hill and I can see a fire in the woods...\n",
      "There's an emergency evacuation happening now in the building across the street\n",
      "I'm afraid that the tornado is coming to our area...\n"
     ]
    }
   ],
   "source": [
    "# check examples of disaster tweets (target = 1)\n",
    "disaster_df = train_df[train_df['target'] == 1]\n",
    "\n",
    "for tweet in disaster_df['text'].values[1:10]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f150652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 54)\n",
      "[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# count the words in each tweet and turn them into word vectors\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "# check\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df['text'][0:5])\n",
    "print(example_train_vectors[0].todense().shape)\n",
    "print(example_train_vectors[0].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3724da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all vectors\n",
    "train_vectors = count_vectorizer.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a554428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model: linear ridge regression\n",
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c06a17d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59453669, 0.5642787 , 0.64117647])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get f1 score of baseline model\n",
    "scores = model_selection.cross_val_score(clf, \n",
    "                                         train_vectors, \n",
    "                                         train_df['target'], \n",
    "                                         cv = 3, \n",
    "                                         scoring = 'f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025c4189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       869\n",
      "           1       0.77      0.68      0.72       654\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.78      0.76      0.77      1523\n",
      "weighted avg       0.78      0.78      0.77      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.text,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('count_vectorizer', feature_extraction.text.CountVectorizer()),\n",
    "    ('ridge_classifier', linear_model.RidgeClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c01ee040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to save scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "scores_df = pd.DataFrame()\n",
    "\n",
    "def save_scores(model_pipe, X_train, X_test, y_train, y_test, name):\n",
    "  \n",
    "    # calculate predictions\n",
    "    train_pred = model_pipe.predict(X_train)\n",
    "    test_pred = model_pipe.predict(X_test)\n",
    "    \n",
    "    # save f1 scores for each class\n",
    "    f1_train_scores = f1_score(y_train, train_pred, average = None)\n",
    "    for i, f1 in enumerate(f1_train_scores):\n",
    "        if i == 0:\n",
    "            f1_0_train = f1\n",
    "        elif i == 1:\n",
    "            f1_1_train = f1\n",
    "            \n",
    "    f1_test_scores = f1_score(y_test, test_pred, average = None)\n",
    "    for i, f1 in enumerate(f1_test_scores):\n",
    "        if i == 0:\n",
    "            f1_0_test = f1\n",
    "        elif i == 1:\n",
    "            f1_1_test = f1\n",
    "        \n",
    "    # store scores\n",
    "    scores_df.at[name, 'F1_0_Train'] = f1_0_train\n",
    "    scores_df.at[name, 'F1_1_Train'] = f1_1_train\n",
    "    scores_df.at[name, 'F1_Avg_Train'] = f1_score(y_train, train_pred, average = 'macro')\n",
    "    scores_df.at[name, 'F1_0_Test'] = f1_0_test\n",
    "    scores_df.at[name, 'F1_1_Test'] = f1_1_test\n",
    "    scores_df.at[name, 'F1_Avg_Test'] = f1_score(y_test, test_pred, average = 'macro')\n",
    "    \n",
    "    # show scores for this model only (can call scores_df to see all scores)\n",
    "    print(scores_df.loc[name, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d73c0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127fa007",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## No class balancing, no preprocessing (KNN, MNB, RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b723be3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42164b88",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tts on unprocessed data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.text,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c989ee5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       869\n",
      "           1       0.77      0.65      0.71       654\n",
      "\n",
      "    accuracy                           0.77      1523\n",
      "   macro avg       0.77      0.75      0.76      1523\n",
      "weighted avg       0.77      0.77      0.76      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# knn, tfidf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1631d7eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.865827\n",
      "F1_1_Train      0.799016\n",
      "F1_Avg_Train    0.832421\n",
      "F1_0_Test       0.808234\n",
      "F1_1_Test       0.705000\n",
      "F1_Avg_Test     0.756617\n",
      "Name: knn-tfidf-unb, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"knn-tfidf-unb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d828f5a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  F1_1_Test  \\\n",
       "knn-tfidf-unb    0.865827    0.799016      0.832421   0.808234      0.705   \n",
       "\n",
       "               F1_Avg_Test  \n",
       "knn-tfidf-unb     0.756617  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9604b545",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84       869\n",
      "           1       0.87      0.61      0.72       654\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.81      0.77      0.78      1523\n",
      "weighted avg       0.81      0.79      0.78      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multinomial naive bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c35df2a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.910580\n",
      "F1_1_Train      0.859256\n",
      "F1_Avg_Train    0.884918\n",
      "F1_0_Test       0.835836\n",
      "F1_1_Test       0.715695\n",
      "F1_Avg_Test     0.775766\n",
      "Name: mnb-tfidf-unb, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-unb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9190d84b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82       869\n",
      "           1       0.84      0.56      0.67       654\n",
      "\n",
      "    accuracy                           0.76      1523\n",
      "   macro avg       0.79      0.74      0.74      1523\n",
      "weighted avg       0.78      0.76      0.75      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('Random Forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4df9d4d2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.997409\n",
      "F1_1_Train      0.996561\n",
      "F1_Avg_Train    0.996985\n",
      "F1_0_Test       0.816786\n",
      "F1_1_Test       0.672161\n",
      "F1_Avg_Test     0.744474\n",
      "Name: rf-tfidf-unb, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"rf-tfidf-unb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63d7c2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## No class balancing, minimal preprocessing (KNN, MNB, RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df221a9c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# preprocessing: removing spacy stopwords and punctuation, lemmatizing\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # take out stopwords and punctuation\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        \n",
    "        # convert to lemmas\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "            \n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90c1e4e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df['preprocessed_txt'] = train_df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7486344f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed Reason earthquake ALLAH forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near La Ronge Sask Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive wildfire evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo Ruby Alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                   preprocessed_txt  \n",
       "0       1               deed Reason earthquake ALLAH forgive  \n",
       "1       1              forest fire near La Ronge Sask Canada  \n",
       "2       1  resident ask shelter place notify officer evac...  \n",
       "3       1  13,000 people receive wildfire evacuation orde...  \n",
       "4       1  got send photo Ruby Alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c67399a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tts on processed data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.preprocessed_txt,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c92599d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       869\n",
      "           1       0.77      0.63      0.70       654\n",
      "\n",
      "    accuracy                           0.76      1523\n",
      "   macro avg       0.77      0.75      0.75      1523\n",
      "weighted avg       0.76      0.76      0.76      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# knn on preprocessed data\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40caf7a9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.865442\n",
      "F1_1_Train      0.791545\n",
      "F1_Avg_Train    0.828493\n",
      "F1_0_Test       0.805391\n",
      "F1_1_Test       0.696893\n",
      "F1_Avg_Test     0.751142\n",
      "Name: knn-tfidf-unb-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"knn-tfidf-unb-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4252b8da",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       869\n",
      "           1       0.84      0.65      0.73       654\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.78      0.78      1523\n",
      "weighted avg       0.80      0.80      0.79      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multinomial naive bayes on preprocessed text\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f260cd4a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.926736\n",
      "F1_1_Train      0.889803\n",
      "F1_Avg_Train    0.908269\n",
      "F1_0_Test       0.836074\n",
      "F1_1_Test       0.733850\n",
      "F1_Avg_Test     0.784962\n",
      "Name: mnb-tfidf-unb-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-unb-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a3cccb6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       869\n",
      "           1       0.85      0.59      0.70       654\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.80      0.76      0.76      1523\n",
      "weighted avg       0.79      0.78      0.77      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest on preprocessed text\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer()),\n",
    "    ('Random Forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b286be4c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.997554\n",
      "F1_1_Train      0.996749\n",
      "F1_Avg_Train    0.997152\n",
      "F1_0_Test       0.826873\n",
      "F1_1_Test       0.698470\n",
      "F1_Avg_Test     0.762672\n",
      "Name: rf-tfidf-unb-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "save_scores(clf, X_train, X_test, y_train, y_test, \"rf-tfidf-unb-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b67c5204",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996749</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.762672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb-prep</th>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.816786</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.744474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep    0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb         0.910580    0.859256      0.884918   0.835836   \n",
       "rf-tfidf-unb-prep     0.997554    0.996749      0.997152   0.826873   \n",
       "knn-tfidf-unb         0.865827    0.799016      0.832421   0.808234   \n",
       "knn-tfidf-unb-prep    0.865442    0.791545      0.828493   0.805391   \n",
       "rf-tfidf-unb          0.997409    0.996561      0.996985   0.816786   \n",
       "\n",
       "                    F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep   0.733850     0.784962  \n",
       "mnb-tfidf-unb        0.715695     0.775766  \n",
       "rf-tfidf-unb-prep    0.698470     0.762672  \n",
       "knn-tfidf-unb        0.705000     0.756617  \n",
       "knn-tfidf-unb-prep   0.696893     0.751142  \n",
       "rf-tfidf-unb         0.672161     0.744474  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c8343",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Class balancing, minimal preprocessing (KNN, MNB, RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "402b4b35",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# class_weight, undersampling, oversampling, smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fb16da3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# class_weight param\n",
    "# knn: none\n",
    "# mnb: fit_prior = False\n",
    "# rf: class_weight = 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7143195",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# use class_weight param (if avail) WITH other\n",
    "# sampling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c12e40",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Undersampling & class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fad0c72e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as resample_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2bce882",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.preprocessed_txt,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eab1e446",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.848382\n",
      "F1_1_Train      0.789732\n",
      "F1_Avg_Train    0.819057\n",
      "F1_0_Test       0.784667\n",
      "F1_1_Test       0.699686\n",
      "F1_Avg_Test     0.742176\n",
      "Name: knn-tfidf-under-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# undersampled knn on preprocessed data\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                              RandomUnderSampler(),\n",
    "                              KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"knn-tfidf-under-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea6c8ed7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.920773\n",
      "F1_1_Train      0.897189\n",
      "F1_Avg_Train    0.908981\n",
      "F1_0_Test       0.794393\n",
      "F1_1_Test       0.736132\n",
      "F1_Avg_Test     0.765262\n",
      "Name: mnb-tfidf-under-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# undersampled, balanced mnb on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        RandomUnderSampler(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-under-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4e76bd9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.981882\n",
      "F1_1_Train      0.976762\n",
      "F1_Avg_Train    0.979322\n",
      "F1_0_Test       0.814895\n",
      "F1_1_Test       0.712490\n",
      "F1_Avg_Test     0.763692\n",
      "Name: rf-tfidf-under-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# random forest on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        RandomUnderSampler(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"rf-tfidf-under-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b8eac63",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-under-prep</th>\n",
       "      <td>0.920773</td>\n",
       "      <td>0.897189</td>\n",
       "      <td>0.908981</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736132</td>\n",
       "      <td>0.765262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-under-prep</th>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.976762</td>\n",
       "      <td>0.979322</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.712490</td>\n",
       "      <td>0.763692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996749</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.762672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb-prep</th>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.816786</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.744474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-under-prep</th>\n",
       "      <td>0.848382</td>\n",
       "      <td>0.789732</td>\n",
       "      <td>0.819057</td>\n",
       "      <td>0.784667</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>0.742176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep      0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb           0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-under-prep    0.920773    0.897189      0.908981   0.794393   \n",
       "rf-tfidf-under-prep     0.981882    0.976762      0.979322   0.814895   \n",
       "rf-tfidf-unb-prep       0.997554    0.996749      0.997152   0.826873   \n",
       "knn-tfidf-unb           0.865827    0.799016      0.832421   0.808234   \n",
       "knn-tfidf-unb-prep      0.865442    0.791545      0.828493   0.805391   \n",
       "rf-tfidf-unb            0.997409    0.996561      0.996985   0.816786   \n",
       "knn-tfidf-under-prep    0.848382    0.789732      0.819057   0.784667   \n",
       "\n",
       "                      F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep     0.733850     0.784962  \n",
       "mnb-tfidf-unb          0.715695     0.775766  \n",
       "mnb-tfidf-under-prep   0.736132     0.765262  \n",
       "rf-tfidf-under-prep    0.712490     0.763692  \n",
       "rf-tfidf-unb-prep      0.698470     0.762672  \n",
       "knn-tfidf-unb          0.705000     0.756617  \n",
       "knn-tfidf-unb-prep     0.696893     0.751142  \n",
       "rf-tfidf-unb           0.672161     0.744474  \n",
       "knn-tfidf-under-prep   0.699686     0.742176  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b1ba29",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Oversampling and class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f11ea994",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b3220d2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.preprocessed_txt,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6fb8598",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.857022\n",
      "F1_1_Train      0.801646\n",
      "F1_Avg_Train    0.829334\n",
      "F1_0_Test       0.782854\n",
      "F1_1_Test       0.697565\n",
      "F1_Avg_Test     0.740209\n",
      "Name: knn-tfidf-over-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# oversampled knn on preprocessed data\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        RandomOverSampler(),\n",
    "                        KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"knn-tfidf-over-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1385bb80",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.934497\n",
      "F1_1_Train      0.911719\n",
      "F1_Avg_Train    0.923108\n",
      "F1_0_Test       0.797688\n",
      "F1_1_Test       0.734043\n",
      "F1_Avg_Test     0.765865\n",
      "Name: mnb-tfidf-over-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# oversampled, balanced mnb on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        RandomOverSampler(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-over-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "605a1a9c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.997409\n",
      "F1_1_Train      0.996561\n",
      "F1_Avg_Train    0.996985\n",
      "F1_0_Test       0.820513\n",
      "F1_1_Test       0.697797\n",
      "F1_Avg_Test     0.759155\n",
      "Name: rf-tfidf-over-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# oversampled random forest on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        RandomOverSampler(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"rf-tfidf-over-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8d266da",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-under-prep</th>\n",
       "      <td>0.920773</td>\n",
       "      <td>0.897189</td>\n",
       "      <td>0.908981</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736132</td>\n",
       "      <td>0.765262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-under-prep</th>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.976762</td>\n",
       "      <td>0.979322</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.712490</td>\n",
       "      <td>0.763692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996749</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.762672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-over-prep</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>0.759155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb-prep</th>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.816786</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.744474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-under-prep</th>\n",
       "      <td>0.848382</td>\n",
       "      <td>0.789732</td>\n",
       "      <td>0.819057</td>\n",
       "      <td>0.784667</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>0.742176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-over-prep</th>\n",
       "      <td>0.857022</td>\n",
       "      <td>0.801646</td>\n",
       "      <td>0.829334</td>\n",
       "      <td>0.782854</td>\n",
       "      <td>0.697565</td>\n",
       "      <td>0.740209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep      0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb           0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-over-prep     0.934497    0.911719      0.923108   0.797688   \n",
       "mnb-tfidf-under-prep    0.920773    0.897189      0.908981   0.794393   \n",
       "rf-tfidf-under-prep     0.981882    0.976762      0.979322   0.814895   \n",
       "rf-tfidf-unb-prep       0.997554    0.996749      0.997152   0.826873   \n",
       "rf-tfidf-over-prep      0.997409    0.996561      0.996985   0.820513   \n",
       "knn-tfidf-unb           0.865827    0.799016      0.832421   0.808234   \n",
       "knn-tfidf-unb-prep      0.865442    0.791545      0.828493   0.805391   \n",
       "rf-tfidf-unb            0.997409    0.996561      0.996985   0.816786   \n",
       "knn-tfidf-under-prep    0.848382    0.789732      0.819057   0.784667   \n",
       "knn-tfidf-over-prep     0.857022    0.801646      0.829334   0.782854   \n",
       "\n",
       "                      F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep     0.733850     0.784962  \n",
       "mnb-tfidf-unb          0.715695     0.775766  \n",
       "mnb-tfidf-over-prep    0.734043     0.765865  \n",
       "mnb-tfidf-under-prep   0.736132     0.765262  \n",
       "rf-tfidf-under-prep    0.712490     0.763692  \n",
       "rf-tfidf-unb-prep      0.698470     0.762672  \n",
       "rf-tfidf-over-prep     0.697797     0.759155  \n",
       "knn-tfidf-unb          0.705000     0.756617  \n",
       "knn-tfidf-unb-prep     0.696893     0.751142  \n",
       "rf-tfidf-unb           0.672161     0.744474  \n",
       "knn-tfidf-under-prep   0.699686     0.742176  \n",
       "knn-tfidf-over-prep    0.697565     0.740209  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b03b2f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### SMOTE and class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a18ceb23",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f83f913c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.preprocessed_txt,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "021a7dbd",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.453258\n",
      "F1_1_Train      0.669477\n",
      "F1_Avg_Train    0.561367\n",
      "F1_0_Test       0.422778\n",
      "F1_1_Test       0.645469\n",
      "F1_Avg_Test     0.534124\n",
      "Name: knn-tfidf-smote-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smote knn on preprocessed data\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        SMOTE(),\n",
    "                        KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"knn-tfidf-smote-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "979d40e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.934886\n",
      "F1_1_Train      0.913268\n",
      "F1_Avg_Train    0.924077\n",
      "F1_0_Test       0.798841\n",
      "F1_1_Test       0.737320\n",
      "F1_Avg_Test     0.768080\n",
      "Name: mnb-tfidf-smote-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smote, balanced mnb on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        SMOTE(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-smote-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "847f79de",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.931020\n",
      "F1_1_Train      0.907624\n",
      "F1_Avg_Train    0.919322\n",
      "F1_0_Test       0.801615\n",
      "F1_1_Test       0.737805\n",
      "F1_Avg_Test     0.769710\n",
      "Name: mnb-tfidf-smote-def-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smote, default mnb on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        SMOTE(),\n",
    "                        MultinomialNB())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"mnb-tfidf-smote-def-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8998ab5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.997554\n",
      "F1_1_Train      0.996750\n",
      "F1_Avg_Train    0.997152\n",
      "F1_0_Test       0.827550\n",
      "F1_1_Test       0.701345\n",
      "F1_Avg_Test     0.764448\n",
      "Name: rf-tfidf-smote-prep, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smote random forest on preprocessed text\n",
    "\n",
    "clf = resample_pipeline(TfidfVectorizer(),\n",
    "                        SMOTE(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "save_scores(clf, X_train, X_test, y_train, y_test, \"rf-tfidf-smote-prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0bfa68e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b5ba3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# spaCy Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19aee63",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## MNB, no class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6baf7c88",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed Reason earthquake ALLAH forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near La Ronge Sask Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive wildfire evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo Ruby Alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                   preprocessed_txt  \n",
       "0       1               deed Reason earthquake ALLAH forgive  \n",
       "1       1              forest fire near La Ronge Sask Canada  \n",
       "2       1  resident ask shelter place notify officer evac...  \n",
       "3       1  13,000 people receive wildfire evacuation orde...  \n",
       "4       1  got send photo Ruby Alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6eba1f9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84e66a7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make spacy vectors (takes awhile!)\n",
    "train_df['spacy_vector'] = train_df['text'].apply(lambda x: nlp(x).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd8dc619",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.spacy_vector.values,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "733f31d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eea3c4d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf00d168",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.707195\n",
      "F1_1_Train      0.628678\n",
      "F1_Avg_Train    0.667937\n",
      "F1_0_Test       0.704639\n",
      "F1_1_Test       0.625465\n",
      "F1_Avg_Test     0.665052\n",
      "Name: mnb-spacyvec-unb, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-under-prep</th>\n",
       "      <td>0.920773</td>\n",
       "      <td>0.897189</td>\n",
       "      <td>0.908981</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736132</td>\n",
       "      <td>0.765262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-smote-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.827550</td>\n",
       "      <td>0.701345</td>\n",
       "      <td>0.764448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-under-prep</th>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.976762</td>\n",
       "      <td>0.979322</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.712490</td>\n",
       "      <td>0.763692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996749</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.762672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-over-prep</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>0.759155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb-prep</th>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.816786</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.744474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-under-prep</th>\n",
       "      <td>0.848382</td>\n",
       "      <td>0.789732</td>\n",
       "      <td>0.819057</td>\n",
       "      <td>0.784667</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>0.742176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-over-prep</th>\n",
       "      <td>0.857022</td>\n",
       "      <td>0.801646</td>\n",
       "      <td>0.829334</td>\n",
       "      <td>0.782854</td>\n",
       "      <td>0.697565</td>\n",
       "      <td>0.740209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-spacyvec-unb</th>\n",
       "      <td>0.707195</td>\n",
       "      <td>0.628678</td>\n",
       "      <td>0.667937</td>\n",
       "      <td>0.704639</td>\n",
       "      <td>0.625465</td>\n",
       "      <td>0.665052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-smote-prep</th>\n",
       "      <td>0.453258</td>\n",
       "      <td>0.669477</td>\n",
       "      <td>0.561367</td>\n",
       "      <td>0.422778</td>\n",
       "      <td>0.645469</td>\n",
       "      <td>0.534124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "mnb-tfidf-under-prep        0.920773    0.897189      0.908981   0.794393   \n",
       "rf-tfidf-smote-prep         0.997554    0.996750      0.997152   0.827550   \n",
       "rf-tfidf-under-prep         0.981882    0.976762      0.979322   0.814895   \n",
       "rf-tfidf-unb-prep           0.997554    0.996749      0.997152   0.826873   \n",
       "rf-tfidf-over-prep          0.997409    0.996561      0.996985   0.820513   \n",
       "knn-tfidf-unb               0.865827    0.799016      0.832421   0.808234   \n",
       "knn-tfidf-unb-prep          0.865442    0.791545      0.828493   0.805391   \n",
       "rf-tfidf-unb                0.997409    0.996561      0.996985   0.816786   \n",
       "knn-tfidf-under-prep        0.848382    0.789732      0.819057   0.784667   \n",
       "knn-tfidf-over-prep         0.857022    0.801646      0.829334   0.782854   \n",
       "mnb-spacyvec-unb            0.707195    0.628678      0.667937   0.704639   \n",
       "knn-tfidf-smote-prep        0.453258    0.669477      0.561367   0.422778   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  \n",
       "mnb-tfidf-under-prep       0.736132     0.765262  \n",
       "rf-tfidf-smote-prep        0.701345     0.764448  \n",
       "rf-tfidf-under-prep        0.712490     0.763692  \n",
       "rf-tfidf-unb-prep          0.698470     0.762672  \n",
       "rf-tfidf-over-prep         0.697797     0.759155  \n",
       "knn-tfidf-unb              0.705000     0.756617  \n",
       "knn-tfidf-unb-prep         0.696893     0.751142  \n",
       "rf-tfidf-unb               0.672161     0.744474  \n",
       "knn-tfidf-under-prep       0.699686     0.742176  \n",
       "knn-tfidf-over-prep        0.697565     0.740209  \n",
       "mnb-spacyvec-unb           0.625465     0.665052  \n",
       "knn-tfidf-smote-prep       0.645469     0.534124  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnb, spacy word vectors\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(scaled_train_embed, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            scaled_train_embed, \n",
    "            scaled_test_embed, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"mnb-spacyvec-unb\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a790b573",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## KNN, no class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a8638eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.842459\n",
      "F1_1_Train      0.776741\n",
      "F1_Avg_Train    0.809600\n",
      "F1_0_Test       0.754886\n",
      "F1_1_Test       0.650199\n",
      "F1_Avg_Test     0.702542\n",
      "Name: knn-spacyvec-unb, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-under-prep</th>\n",
       "      <td>0.920773</td>\n",
       "      <td>0.897189</td>\n",
       "      <td>0.908981</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.736132</td>\n",
       "      <td>0.765262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-smote-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.827550</td>\n",
       "      <td>0.701345</td>\n",
       "      <td>0.764448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-under-prep</th>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.976762</td>\n",
       "      <td>0.979322</td>\n",
       "      <td>0.814895</td>\n",
       "      <td>0.712490</td>\n",
       "      <td>0.763692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb-prep</th>\n",
       "      <td>0.997554</td>\n",
       "      <td>0.996749</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.698470</td>\n",
       "      <td>0.762672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-over-prep</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>0.759155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb</th>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.799016</td>\n",
       "      <td>0.832421</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.756617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-unb-prep</th>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.805391</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf-tfidf-unb</th>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.996561</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.816786</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.744474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-under-prep</th>\n",
       "      <td>0.848382</td>\n",
       "      <td>0.789732</td>\n",
       "      <td>0.819057</td>\n",
       "      <td>0.784667</td>\n",
       "      <td>0.699686</td>\n",
       "      <td>0.742176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-over-prep</th>\n",
       "      <td>0.857022</td>\n",
       "      <td>0.801646</td>\n",
       "      <td>0.829334</td>\n",
       "      <td>0.782854</td>\n",
       "      <td>0.697565</td>\n",
       "      <td>0.740209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-spacyvec-unb</th>\n",
       "      <td>0.842459</td>\n",
       "      <td>0.776741</td>\n",
       "      <td>0.809600</td>\n",
       "      <td>0.754886</td>\n",
       "      <td>0.650199</td>\n",
       "      <td>0.702542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-spacyvec-unb</th>\n",
       "      <td>0.707195</td>\n",
       "      <td>0.628678</td>\n",
       "      <td>0.667937</td>\n",
       "      <td>0.704639</td>\n",
       "      <td>0.625465</td>\n",
       "      <td>0.665052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn-tfidf-smote-prep</th>\n",
       "      <td>0.453258</td>\n",
       "      <td>0.669477</td>\n",
       "      <td>0.561367</td>\n",
       "      <td>0.422778</td>\n",
       "      <td>0.645469</td>\n",
       "      <td>0.534124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "mnb-tfidf-under-prep        0.920773    0.897189      0.908981   0.794393   \n",
       "rf-tfidf-smote-prep         0.997554    0.996750      0.997152   0.827550   \n",
       "rf-tfidf-under-prep         0.981882    0.976762      0.979322   0.814895   \n",
       "rf-tfidf-unb-prep           0.997554    0.996749      0.997152   0.826873   \n",
       "rf-tfidf-over-prep          0.997409    0.996561      0.996985   0.820513   \n",
       "knn-tfidf-unb               0.865827    0.799016      0.832421   0.808234   \n",
       "knn-tfidf-unb-prep          0.865442    0.791545      0.828493   0.805391   \n",
       "rf-tfidf-unb                0.997409    0.996561      0.996985   0.816786   \n",
       "knn-tfidf-under-prep        0.848382    0.789732      0.819057   0.784667   \n",
       "knn-tfidf-over-prep         0.857022    0.801646      0.829334   0.782854   \n",
       "knn-spacyvec-unb            0.842459    0.776741      0.809600   0.754886   \n",
       "mnb-spacyvec-unb            0.707195    0.628678      0.667937   0.704639   \n",
       "knn-tfidf-smote-prep        0.453258    0.669477      0.561367   0.422778   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  \n",
       "mnb-tfidf-under-prep       0.736132     0.765262  \n",
       "rf-tfidf-smote-prep        0.701345     0.764448  \n",
       "rf-tfidf-under-prep        0.712490     0.763692  \n",
       "rf-tfidf-unb-prep          0.698470     0.762672  \n",
       "rf-tfidf-over-prep         0.697797     0.759155  \n",
       "knn-tfidf-unb              0.705000     0.756617  \n",
       "knn-tfidf-unb-prep         0.696893     0.751142  \n",
       "rf-tfidf-unb               0.672161     0.744474  \n",
       "knn-tfidf-under-prep       0.699686     0.742176  \n",
       "knn-tfidf-over-prep        0.697565     0.740209  \n",
       "knn-spacyvec-unb           0.650199     0.702542  \n",
       "mnb-spacyvec-unb           0.625465     0.665052  \n",
       "knn-tfidf-smote-prep       0.645469     0.534124  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knn-spacyvec-unb\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb44d2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## RF, no class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45bcfe71",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.990831\n",
      "F1_1_Train      0.987692\n",
      "F1_Avg_Train    0.989262\n",
      "F1_0_Test       0.801498\n",
      "F1_1_Test       0.684792\n",
      "F1_Avg_Test     0.743145\n",
      "Name: rf-spacyvec-unb, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rf\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rf-spacyvec-unb\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f54c672",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## MNB, class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a738f7b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.676200\n",
      "F1_1_Train      0.653755\n",
      "F1_Avg_Train    0.664977\n",
      "F1_0_Test       0.666240\n",
      "F1_1_Test       0.647773\n",
      "F1_Avg_Test     0.657007\n",
      "Name: mnb-spacyvec-under, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersampled, balanced mnb on preprocessed text\n",
    "\n",
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.spacy_vector.values,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)\n",
    "\n",
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)\n",
    "\n",
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)\n",
    "\n",
    "clf = resample_pipeline(RandomUnderSampler(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "clf.fit(scaled_train_embed, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            scaled_train_embed, \n",
    "            scaled_test_embed, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"mnb-spacyvec-under\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "116eea9f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.676620\n",
      "F1_1_Train      0.653977\n",
      "F1_Avg_Train    0.665298\n",
      "F1_0_Test       0.667093\n",
      "F1_1_Test       0.648211\n",
      "F1_Avg_Test     0.657652\n",
      "Name: mnb-spacyvec-over, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oversampled, balanced mnb on preprocessed text\n",
    "\n",
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.spacy_vector.values,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)\n",
    "\n",
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)\n",
    "\n",
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)\n",
    "\n",
    "clf = resample_pipeline(RandomOverSampler(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "clf.fit(scaled_train_embed, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            scaled_train_embed, \n",
    "            scaled_test_embed, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"mnb-spacyvec-over\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7c227661",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.676298\n",
      "F1_1_Train      0.653290\n",
      "F1_Avg_Train    0.664794\n",
      "F1_0_Test       0.663677\n",
      "F1_1_Test       0.646465\n",
      "F1_Avg_Test     0.655071\n",
      "Name: mnb-spacyvec-smote, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smoted, balanced mnb on preprocessed text\n",
    "\n",
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.spacy_vector.values,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)\n",
    "\n",
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)\n",
    "\n",
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        MultinomialNB(fit_prior = False))\n",
    "clf.fit(scaled_train_embed, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            scaled_train_embed, \n",
    "            scaled_test_embed, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"mnb-spacyvec-smote\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e648f64",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.676284\n",
      "F1_1_Train      0.652248\n",
      "F1_Avg_Train    0.664266\n",
      "F1_0_Test       0.667093\n",
      "F1_1_Test       0.648211\n",
      "F1_Avg_Test     0.657652\n",
      "Name: mnb-spacyvec-smote, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smoted, unbalanced mnb on preprocessed text\n",
    "\n",
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.spacy_vector.values,\n",
    "    train_df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = train_df.target)\n",
    "\n",
    "# sets are of format numpy array of numpy arrays\n",
    "# need to flatten the arrays because clf is expecting\n",
    "# just a 2d numpy array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)\n",
    "\n",
    "# scale values so there are no negative values\n",
    "# MultinomialNB doesn't accept negative values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        MultinomialNB())\n",
    "clf.fit(scaled_train_embed, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            scaled_train_embed, \n",
    "            scaled_test_embed, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"mnb-spacyvec-smote\")\n",
    "\n",
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d820471",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## KNN, class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "512d36a9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.817106\n",
      "F1_1_Train      0.772040\n",
      "F1_Avg_Train    0.794573\n",
      "F1_0_Test       0.720903\n",
      "F1_1_Test       0.654919\n",
      "F1_Avg_Test     0.687911\n",
      "Name: knn-spacyvec-under, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# undersampled knn\n",
    "\n",
    "clf = resample_pipeline(RandomUnderSampler(),\n",
    "                        KNeighborsClassifier(n_neighbors = 5,\n",
    "                                            metric = 'euclidean'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knn-spacyvec-under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0c99a363",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.828014\n",
      "F1_1_Train      0.784922\n",
      "F1_Avg_Train    0.806468\n",
      "F1_0_Test       0.711824\n",
      "F1_1_Test       0.644167\n",
      "F1_Avg_Test     0.677996\n",
      "Name: knn-spacyvec-over, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# oversampled knn\n",
    "\n",
    "clf = resample_pipeline(RandomOverSampler(),\n",
    "                        KNeighborsClassifier(n_neighbors = 5,\n",
    "                                            metric = 'euclidean'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knn-spacyvec-over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "34da746a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.786374\n",
      "F1_1_Train      0.772465\n",
      "F1_Avg_Train    0.779420\n",
      "F1_0_Test       0.654402\n",
      "F1_1_Test       0.654856\n",
      "F1_Avg_Test     0.654629\n",
      "Name: knn-spacyvec-smote, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smoted knn\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        KNeighborsClassifier(n_neighbors = 5,\n",
    "                                            metric = 'euclidean'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knn-spacyvec-smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d710a6d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.812723\n",
      "F1_1_Train      0.768892\n",
      "F1_Avg_Train    0.790808\n",
      "F1_0_Test       0.726521\n",
      "F1_1_Test       0.657797\n",
      "F1_Avg_Test     0.692159\n",
      "Name: knndef-spacyvec-under, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# undersampled default knn\n",
    "\n",
    "clf = resample_pipeline(RandomUnderSampler(),\n",
    "                        KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knndef-spacyvec-under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "341470a0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.826461\n",
      "F1_1_Train      0.784847\n",
      "F1_Avg_Train    0.805654\n",
      "F1_0_Test       0.720238\n",
      "F1_1_Test       0.655930\n",
      "F1_Avg_Test     0.688084\n",
      "Name: knndef-spacyvec-over, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# oversampled default knn\n",
    "\n",
    "clf = resample_pipeline(RandomOverSampler(),\n",
    "                        KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knndef-spacyvec-over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "149a2519",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.785256\n",
      "F1_1_Train      0.774411\n",
      "F1_Avg_Train    0.779834\n",
      "F1_0_Test       0.650667\n",
      "F1_1_Test       0.661061\n",
      "F1_Avg_Test     0.655864\n",
      "Name: knndef-spacyvec-smote, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# smoted default knn\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        KNeighborsClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"knndef-spacyvec-smote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d301303",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## RF, class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ee3ec46",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.966774\n",
      "F1_1_Train      0.957977\n",
      "F1_Avg_Train    0.962376\n",
      "F1_0_Test       0.779236\n",
      "F1_1_Test       0.700696\n",
      "F1_Avg_Test     0.739966\n",
      "Name: rf-spacyvec-under, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf under\n",
    "\n",
    "clf = resample_pipeline(RandomUnderSampler(),\n",
    "                        RandomForestClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rf-spacyvec-under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3f170c74",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.963695\n",
      "F1_1_Train      0.954478\n",
      "F1_Avg_Train    0.959087\n",
      "F1_0_Test       0.774453\n",
      "F1_1_Test       0.700306\n",
      "F1_Avg_Test     0.737380\n",
      "Name: rfbal-spacyvec-under, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf under bal\n",
    "\n",
    "clf = resample_pipeline(RandomUnderSampler(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rfbal-spacyvec-under\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "095dedfa",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.990085\n",
      "F1_1_Train      0.986784\n",
      "F1_Avg_Train    0.988434\n",
      "F1_0_Test       0.797157\n",
      "F1_1_Test       0.695152\n",
      "F1_Avg_Test     0.746154\n",
      "Name: rf-spacyvec-over, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf over\n",
    "\n",
    "clf = resample_pipeline(RandomOverSampler(),\n",
    "                        RandomForestClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rf-spacyvec-over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2bb47ce4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.990515\n",
      "F1_1_Train      0.987361\n",
      "F1_Avg_Train    0.988938\n",
      "F1_0_Test       0.795640\n",
      "F1_1_Test       0.690339\n",
      "F1_Avg_Test     0.742989\n",
      "Name: rfbal-spacyvec-over, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf over bal\n",
    "\n",
    "clf = resample_pipeline(RandomOverSampler(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rfbal-spacyvec-over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6346b8e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.990815\n",
      "F1_1_Train      0.987721\n",
      "F1_Avg_Train    0.989268\n",
      "F1_0_Test       0.797357\n",
      "F1_1_Test       0.700813\n",
      "F1_Avg_Test     0.749085\n",
      "Name: rf-spacyvec-smote, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf smote\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        RandomForestClassifier())\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rf-spacyvec-smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a81c2a2d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.990826\n",
      "F1_1_Train      0.987702\n",
      "F1_Avg_Train    0.989264\n",
      "F1_0_Test       0.795806\n",
      "F1_1_Test       0.700162\n",
      "F1_Avg_Test     0.747984\n",
      "Name: rfbal-spacyvec-smote, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# rf smote with balancing\n",
    "\n",
    "clf = resample_pipeline(SMOTE(),\n",
    "                        RandomForestClassifier(class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"rfbal-spacyvec-smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "044a5677",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb-prep</th>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.889803</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>0.836074</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.784962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-unb</th>\n",
       "      <td>0.910580</td>\n",
       "      <td>0.859256</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>0.715695</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-def-prep</th>\n",
       "      <td>0.931020</td>\n",
       "      <td>0.907624</td>\n",
       "      <td>0.919322</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.769710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-smote-prep</th>\n",
       "      <td>0.934886</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.924077</td>\n",
       "      <td>0.798841</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.768080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnb-tfidf-over-prep</th>\n",
       "      <td>0.934497</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.923108</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.765865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  \\\n",
       "mnb-tfidf-unb-prep          0.926736    0.889803      0.908269   0.836074   \n",
       "mnb-tfidf-unb               0.910580    0.859256      0.884918   0.835836   \n",
       "mnb-tfidf-smote-def-prep    0.931020    0.907624      0.919322   0.801615   \n",
       "mnb-tfidf-smote-prep        0.934886    0.913268      0.924077   0.798841   \n",
       "mnb-tfidf-over-prep         0.934497    0.911719      0.923108   0.797688   \n",
       "\n",
       "                          F1_1_Test  F1_Avg_Test  \n",
       "mnb-tfidf-unb-prep         0.733850     0.784962  \n",
       "mnb-tfidf-unb              0.715695     0.775766  \n",
       "mnb-tfidf-smote-def-prep   0.737805     0.769710  \n",
       "mnb-tfidf-smote-prep       0.737320     0.768080  \n",
       "mnb-tfidf-over-prep        0.734043     0.765865  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = 'F1_Avg_Test', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c900490",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Gensim word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ae435a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1c20bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1683710",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04042ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# balance classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3bcabb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# preprocess and get gensim doc vector\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def preprocess_and_vectorize(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_punct or token.is_stop:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return wv.get_mean_vector(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7bb4d27",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert text into gensim word embeddings\n",
    "\n",
    "df['gensim_vector'] = df['text'].apply(lambda text: preprocess_and_vectorize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b633f5ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>gensim_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.05016107, 0.00387215, 0.047061782, 0.028958...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.03064329, 0.0030595234, 0.0369662, 0.020602...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0048536863, 0.011481234, 0.016771162, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.060398173, -0.012511074, -0.0018801317, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.021673834, 0.0012636562, -0.031610973, 0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                      gensim_vector  \n",
       "0       1  [0.05016107, 0.00387215, 0.047061782, 0.028958...  \n",
       "1       1  [0.03064329, 0.0030595234, 0.0369662, 0.020602...  \n",
       "2       1  [-0.0048536863, 0.011481234, 0.016771162, -0.0...  \n",
       "3       1  [0.060398173, -0.012511074, -0.0018801317, 0.0...  \n",
       "4       1  [0.021673834, 0.0012636562, -0.031610973, 0.03...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e5fe6a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.gensim_vector.values,\n",
    "    df.target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 2022,\n",
    "    stratify = df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de3c621",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create 2d np arrays for X train and test sets\n",
    "import numpy as np\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a4be949",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0_Train      0.891286\n",
      "F1_1_Train      0.841212\n",
      "F1_Avg_Train    0.866249\n",
      "F1_0_Test       0.816304\n",
      "F1_1_Test       0.737849\n",
      "F1_Avg_Test     0.777076\n",
      "Name: gbc-gensim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "save_scores(clf, \n",
    "            X_train_2d, \n",
    "            X_test_2d, \n",
    "            y_train, \n",
    "            y_test, \n",
    "            \"gbc-gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffd97049",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_0_Train</th>\n",
       "      <th>F1_1_Train</th>\n",
       "      <th>F1_Avg_Train</th>\n",
       "      <th>F1_0_Test</th>\n",
       "      <th>F1_1_Test</th>\n",
       "      <th>F1_Avg_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gbc-gensim</th>\n",
       "      <td>0.891286</td>\n",
       "      <td>0.841212</td>\n",
       "      <td>0.866249</td>\n",
       "      <td>0.816304</td>\n",
       "      <td>0.737849</td>\n",
       "      <td>0.777076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            F1_0_Train  F1_1_Train  F1_Avg_Train  F1_0_Test  F1_1_Test  \\\n",
       "gbc-gensim    0.891286    0.841212      0.866249   0.816304   0.737849   \n",
       "\n",
       "            F1_Avg_Test  \n",
       "gbc-gensim     0.777076  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by = \"F1_Avg_Test\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda21f6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "more gensim:\n",
    "other models available:\n",
    "- twitter, wiki\n",
    "- glove, fasttext\n",
    "\n",
    "consider gensim models:\n",
    "- glove-twitter-200\n",
    "- word2vec-google-news-300\n",
    "- glove-wiki-gigaword-300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c849dc",
   "metadata": {},
   "source": [
    "# Fast Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004f6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in kaggle's training data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d759f01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape and head\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38860b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['__label__1', '__label__0'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format target labels for fasttext:\n",
    "# must have \"__label__\" before each target lable\n",
    "df['target'] = \"__label__\" + df['target'].astype(str)\n",
    "\n",
    "# check\n",
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da9780e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    __label__1 Our Deeds are the Reason of this #e...\n",
       "1    __label__1 Forest fire near La Ronge Sask. Canada\n",
       "2    __label__1 All residents asked to 'shelter in ...\n",
       "3    __label__1 13,000 people receive #wildfires ev...\n",
       "4    __label__1 Just got sent this photo from Ruby ...\n",
       "Name: target_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge target and text columns so the text is on the same line as the label\n",
    "# with the label first (separated by a space); this is required for \n",
    "# fasttext formatting\n",
    "df['target_text'] = df['target'] + \" \" + df['text']\n",
    "\n",
    "# check\n",
    "df.target_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e51166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    __label__1 our deeds are the reason of this ea...\n",
       "1     __label__1 forest fire near la ronge sask canada\n",
       "2    __label__1 all residents asked to 'shelter in ...\n",
       "3    __label__1 13 000 people receive wildfires eva...\n",
       "4    __label__1 just got sent this photo from ruby ...\n",
       "Name: target_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define preprocess function\n",
    "\n",
    "import re\n",
    "\n",
    "# preprocess function subs everything that's not a word character or \n",
    "# is a space character or is an apostrophe with a space, then subs all\n",
    "# multiple spaces with just one space, then strips leading and lagging spaces\n",
    "# and converts all letters to lowercase, then subs newline characters with a\n",
    "# single space and subs all multiple spaces with just one space again\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"[^\\w\\s\\']\", \" \", text)\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r\"\\\\n+\", \" \", text)\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    return text\n",
    "\n",
    "# apply preprocess function to target_text column\n",
    "df['target_text'] = df['target_text'].map(preprocess)\n",
    "\n",
    "# check\n",
    "df.target_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ce80890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    our deeds are the reason of this earthquake ma...\n",
       "1                forest fire near la ronge sask canada\n",
       "2    all residents asked to 'shelter in place' are ...\n",
       "3    13 000 people receive wildfires evacuation ord...\n",
       "4    just got sent this photo from ruby alaska as s...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make preprocessed text column (without label) to test model on\n",
    "df['processed_text'] = df['text'].map(preprocess)\n",
    "\n",
    "# check\n",
    "df.processed_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bfaae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6090, 7)\n",
      "(1523, 7)\n"
     ]
    }
   ],
   "source": [
    "# tts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, \n",
    "                               test_size = 0.2, \n",
    "                               random_state = 2022,\n",
    "                               stratify = df.target)\n",
    "\n",
    "# check\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21925e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save formatted and labeled column in file for fasttext to train on\n",
    "\n",
    "import csv\n",
    "\n",
    "train.to_csv(\"disaster_train_fasttext.csv\", \n",
    "             columns = [\"target_text\"], \n",
    "             index = False, \n",
    "             header = False,\n",
    "             quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e8602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [75 lines of output]\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\setuptools\\dist.py:755: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Usage of dash-separated 'description-file' will not be supported in future\n",
      "          versions. Please use the underscore name 'description_file' instead.\n",
      "  \n",
      "          By 2023-Sep-26, you need to update your project and remove deprecated calls\n",
      "          or your builds will no longer be supported.\n",
      "  \n",
      "          See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    opt = self.warn_dash_deprecation(opt, section)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-310\n",
      "  creating build\\lib.win-amd64-cpython-310\\fasttext\n",
      "  copying python\\fasttext_module\\fasttext\\FastText.py -> build\\lib.win-amd64-cpython-310\\fasttext\n",
      "  copying python\\fasttext_module\\fasttext\\__init__.py -> build\\lib.win-amd64-cpython-310\\fasttext\n",
      "  creating build\\lib.win-amd64-cpython-310\\fasttext\\util\n",
      "  copying python\\fasttext_module\\fasttext\\util\\util.py -> build\\lib.win-amd64-cpython-310\\fasttext\\util\n",
      "  copying python\\fasttext_module\\fasttext\\util\\__init__.py -> build\\lib.win-amd64-cpython-310\\fasttext\\util\n",
      "  creating build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
      "  copying python\\fasttext_module\\fasttext\\tests\\test_configurations.py -> build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
      "  copying python\\fasttext_module\\fasttext\\tests\\test_script.py -> build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
      "  copying python\\fasttext_module\\fasttext\\tests\\__init__.py -> build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
      "  running build_ext\n",
      "  building 'fasttext_pybind' extension\n",
      "  creating build\\temp.win-amd64-cpython-310\n",
      "  creating build\\temp.win-amd64-cpython-310\\Release\n",
      "  creating build\\temp.win-amd64-cpython-310\\Release\\python\n",
      "  creating build\\temp.win-amd64-cpython-310\\Release\\python\\fasttext_module\n",
      "  creating build\\temp.win-amd64-cpython-310\\Release\\python\\fasttext_module\\fasttext\n",
      "  creating build\\temp.win-amd64-cpython-310\\Release\\python\\fasttext_module\\fasttext\\pybind\n",
      "  creating build\\temp.win-amd64-cpython-310\\Release\\src\n",
      "  \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.36.32532\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include -IC:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include -Isrc -IC:\\Users\\yang0108\\AppData\\Local\\anaconda3\\include -IC:\\Users\\yang0108\\AppData\\Local\\anaconda3\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.36.32532\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.36.32532\\ATLMFC\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22000.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tppython/fasttext_module/fasttext/pybind/fasttext_pybind.cc /Fobuild\\temp.win-amd64-cpython-310\\Release\\python/fasttext_module/fasttext/pybind/fasttext_pybind.obj /EHsc /DVERSION_INFO=\\\\\\\"0.9.2\\\\\\\"\n",
      "  fasttext_pybind.cc\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(171): error C2065: 'ssize_t': undeclared identifier\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(171): error C2672: 'pybind11::init': no matching overloaded function found\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1924): note: could be 'Ret pybind11::init(CFunc &&,AFunc &&)'\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(171): note: 'pybind11::init': invalid template argument for 'CFunc', type expected\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1916): note: or       'Ret pybind11::init(Func &&)'\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(171): note: 'pybind11::init': invalid template argument for 'Func', type expected\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1904): note: or       'pybind11::detail::initimpl::constructor<Args...> pybind11::init(void)'\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(171): note: 'pybind11::init': invalid template argument for 'Args', type expected\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(171): error C2672: 'pybind11::class_<fasttext::Vector>::def': no matching overloaded function found\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1624): note: could be 'pybind11::class_<fasttext::Vector> &pybind11::class_<fasttext::Vector>::def(pybind11::detail::initimpl::pickle_factory<Args...> &&,const Extra &...)'\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1618): note: or       'pybind11::class_<fasttext::Vector> &pybind11::class_<fasttext::Vector>::def(pybind11::detail::initimpl::factory<Args...> &&,const Extra &...)'\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1611): note: or       'pybind11::class_<fasttext::Vector> &pybind11::class_<fasttext::Vector>::def(const pybind11::detail::initimpl::alias_constructor<Args...> &,const Extra &...)'\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1604): note: or       'pybind11::class_<fasttext::Vector> &pybind11::class_<fasttext::Vector>::def(const pybind11::detail::initimpl::constructor<Args...> &,const Extra &...)'\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1592): note: or       'pybind11::class_<fasttext::Vector> &pybind11::class_<fasttext::Vector>::def(const T &,const Extra &...)'\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1567): note: or       'pybind11::class_<fasttext::Vector> &pybind11::class_<fasttext::Vector>::def(const char *,Func &&,const Extra &...)'\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(171): note: 'pybind11::class_<fasttext::Vector> &pybind11::class_<fasttext::Vector>::def(const char *,Func &&,const Extra &...)': expects 3 arguments - 1 provided\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(185): error C2065: 'ssize_t': undeclared identifier\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(185): error C2065: 'ssize_t': undeclared identifier\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(185): error C2672: 'pybind11::init': no matching overloaded function found\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1924): note: could be 'Ret pybind11::init(CFunc &&,AFunc &&)'\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(185): note: 'pybind11::init': invalid template argument for 'CFunc', type expected\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1916): note: or       'Ret pybind11::init(Func &&)'\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(185): note: 'pybind11::init': invalid template argument for 'Func', type expected\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1904): note: or       'pybind11::detail::initimpl::constructor<Args...> pybind11::init(void)'\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(185): note: 'pybind11::init': invalid template argument for 'Args', type expected\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(185): error C2672: 'pybind11::class_<fasttext::DenseMatrix>::def': no matching overloaded function found\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1624): note: could be 'pybind11::class_<fasttext::DenseMatrix> &pybind11::class_<fasttext::DenseMatrix>::def(pybind11::detail::initimpl::pickle_factory<Args...> &&,const Extra &...)'\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1618): note: or       'pybind11::class_<fasttext::DenseMatrix> &pybind11::class_<fasttext::DenseMatrix>::def(pybind11::detail::initimpl::factory<Args...> &&,const Extra &...)'\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1611): note: or       'pybind11::class_<fasttext::DenseMatrix> &pybind11::class_<fasttext::DenseMatrix>::def(const pybind11::detail::initimpl::alias_constructor<Args...> &,const Extra &...)'\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1604): note: or       'pybind11::class_<fasttext::DenseMatrix> &pybind11::class_<fasttext::DenseMatrix>::def(const pybind11::detail::initimpl::constructor<Args...> &,const Extra &...)'\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1592): note: or       'pybind11::class_<fasttext::DenseMatrix> &pybind11::class_<fasttext::DenseMatrix>::def(const T &,const Extra &...)'\n",
      "  C:\\Users\\yang0108\\AppData\\Local\\anaconda3\\lib\\site-packages\\pybind11\\include\\pybind11\\pybind11.h(1567): note: or       'pybind11::class_<fasttext::DenseMatrix> &pybind11::class_<fasttext::DenseMatrix>::def(const char *,Func &&,const Extra &...)'\n",
      "  python/fasttext_module/fasttext/pybind/fasttext_pybind.cc(185): note: 'pybind11::class_<fasttext::DenseMatrix> &pybind11::class_<fasttext::DenseMatrix>::def(const char *,Func &&,const Extra &...)': expects 3 arguments - 1 provided\n",
      "  error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.36.32532\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for fasttext\n",
      "ERROR: Could not build wheels for fasttext, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached fasttext-0.9.2.tar.gz (68 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\lib\\site-packages (from fasttext) (2.10.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\yang0108\\appdata\\local\\anaconda3\\lib\\site-packages (from fasttext) (67.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yang0108\\appdata\\local\\anaconda3\\lib\\site-packages (from fasttext) (1.23.5)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py): started\n",
      "  Building wheel for fasttext (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for fasttext\n",
      "Failed to build fasttext\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8760d544",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa12cd85",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# train model with labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mtrain_supervised(\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisaster_train_fasttext.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "# train model with labels\n",
    "model = fasttext.train_supervised(input = 'disaster_train_fasttext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model\n",
    "model.predict(\"hello how are you\")\n",
    "\n",
    "# THIS KILLS MY KERNEL EVERY TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5491e1c3",
   "metadata": {},
   "source": [
    "# IGNORE BELOW HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "537fffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "print(len(test.processed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f02182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make file with processed text (without labels) in test set\n",
    "# to test model on\n",
    "\n",
    "test.to_csv(\"disaster_test_fasttext.csv\", \n",
    "             columns = [\"processed_text\"], \n",
    "             index = False, \n",
    "             header = False,\n",
    "             quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feaea01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "print(len(test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a626d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make file with true labels for test set to compare model predictions to\n",
    "\n",
    "test.to_csv(\"disaster_test_fasttext_true_labels.csv\",\n",
    "           columns = ['target'],\n",
    "           index = False,\n",
    "           header = False,\n",
    "           quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4485fe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n",
      "                                                   0\n",
      "0  had a nightmare and was about to jump out of b...\n",
      "1  mumbai24x7 helping hand in mumbai 2 ttes take ...\n",
      "2  pandemonium in aba as woman delivers baby with...\n",
      "3  whereas jez will obliterate the national debt ...\n",
      "4                               dust storm in riyadh\n",
      "5  savings and sewing in guatemala savings and se...\n",
      "6  israeli helicopters that attacked civilians in...\n",
      "7  amirkingkhan you would have been annihilated s...\n",
      "8    going to go drown my sorrows with sad music brb\n",
      "9  'how many men would a human hew if a human cou...\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "# with open('disaster_test_fasttext.csv', 'r', encoding = 'utf-8') as f:\n",
    "#     test_data = f.readlines()\n",
    "\n",
    "test_data = pd.read_csv(\"disaster_test_fasttext.csv\", \n",
    "                        header = None,\n",
    "                        quoting = csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "print(len(test_data))\n",
    "    \n",
    "# check\n",
    "print(test_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "839d348e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'had a nightmare and was about to jump out of bed when i remembered my injury alas it was too late and i screamed in my bedroom'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09a90c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newline characters\n",
    "# test_data = [line.strip() for line in test_data]\n",
    "\n",
    "# check\n",
    "# print(test_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10fe9164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "# check length of test data\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a51151cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['had a nightmare and was about to jump out of bed when i remembered my injury alas it was too late and i screamed in my bedroom',\n",
       " 'mumbai24x7 helping hand in mumbai 2 ttes take charge of helpline to calm anxious relatives the ind http t co tuaryijpqu mumbai',\n",
       " 'pandemonium in aba as woman delivers baby without face photos http t co acfi2rhz4n',\n",
       " 'whereas jez will obliterate the national debt and give lots of new benefits by simply printing money genius https t co reffbkvg9r',\n",
       " 'dust storm in riyadh',\n",
       " 'savings and sewing in guatemala savings and sewing in guatemala when a natural disaster hit seamstress elvia http t co jdx9ox2kik',\n",
       " 'israeli helicopters that attacked civilians in gaza just completed exercises in greece',\n",
       " 'amirkingkhan you would have been annihilated so you might as well thank floydmayweather',\n",
       " 'going to go drown my sorrows with sad music brb',\n",
       " \"'how many men would a human hew if a human could hew men '\\n\\n popular tongue twister among woodchucks\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert test data to list\n",
    "test_data_list = test_data[0].tolist()\n",
    "\n",
    "# check\n",
    "test_data_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60f48396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n",
      "            0\n",
      "0  __label__0\n",
      "1  __label__1\n",
      "2  __label__0\n",
      "3  __label__1\n",
      "4  __label__1\n",
      "5  __label__1\n",
      "6  __label__1\n",
      "7  __label__0\n",
      "8  __label__0\n",
      "9  __label__0\n"
     ]
    }
   ],
   "source": [
    "true_labels = pd.read_csv(\"disaster_test_fasttext_true_labels.csv\", \n",
    "                        header = None,\n",
    "                        quoting = csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "print(len(true_labels))\n",
    "    \n",
    "# check\n",
    "print(true_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d242d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1523\n"
     ]
    }
   ],
   "source": [
    "# check length of true_labels\n",
    "print(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7e44fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__0',\n",
       " '__label__1',\n",
       " '__label__0',\n",
       " '__label__1',\n",
       " '__label__1',\n",
       " '__label__1',\n",
       " '__label__1',\n",
       " '__label__0',\n",
       " '__label__0',\n",
       " '__label__0']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert true labels to list\n",
    "true_labels_list = true_labels[0].tolist()\n",
    "\n",
    "# check\n",
    "true_labels_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d5a88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line of code kills the kernel\n",
    "\n",
    "# predict labels for test data\n",
    "# model.predict(test_data[0][0])\n",
    "# predictions = [model.predict(line)[0] for line in test_data.iterrows()]\n",
    "\n",
    "# check\n",
    "# print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bfa35da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check length of predictions\n",
    "# print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80dbae4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'had a nightmare and was about to jump out of bed when i remembered my injury alas it was too late and i screamed in my bedroom'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is causing my kernel to crash\n",
    "# https://fasttext.cc/docs/en/supervised-tutorial.html\n",
    "\n",
    "model.predict(\"which baking dish is best to bake a banana bread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01122b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_prediction = model.predict(test_data_list[0])\n",
    "# test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a642bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the f1 score\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# f1 = f1_score(true_labels, predictions, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ee335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model.test(\"disaster_test_fasttext\")\n",
    "\n",
    "# # three output numbers: size of test samples, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get f1?\n",
    "# model.test_label(\"disaster_test_fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c98eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(\"disaster_test_fasttext\")\n",
    "\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ea631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad88bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e60a567a",
   "metadata": {},
   "source": [
    "# Other\n",
    "\n",
    "categorical nb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45e00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
